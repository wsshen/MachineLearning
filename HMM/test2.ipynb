{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_states = 2\n",
    "\n",
    "model = hmm.CategoricalHMM(n_components=hmm_states)\n",
    "model.emissionprob_ = np.array([[0.6,0.4],[0.1,0.9]])\n",
    "model.transmat_ = np.array([[0.8,0.2],[0.1,0.9]])\n",
    "model.startprob_ = np.array([0.4,0.6])\n",
    "data,states = model.sample(n_samples = 1000,random_state=28)\n",
    "data = np.squeeze(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1\n",
      " 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1\n",
      " 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0\n",
      " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0 0 0 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states = 2\n",
    "n_features = 2\n",
    "n_obs = data.shape[0]\n",
    "# emission = np.random.rand(n_obs,n_states)\n",
    "# emission = emission/np.tile(np.expand_dims(np.sum(emission,axis=1),axis=1),(1,2))\n",
    "\n",
    "# emission = np.random.rand(n_states,n_features)\n",
    "# emission = emission/np.tile(np.expand_dims(np.sum(emission,axis=1),axis=1),(1,2))\n",
    "emission = np.array([[0.2,0.8],[0.3,0.7]])\n",
    "\n",
    "# transition =  np.random.rand(n_states,n_states)\n",
    "# transition = transition/np.tile(np.expand_dims(np.sum(transition,axis=1),axis=1),(1,2))\n",
    "transition = np.array([[0.5,0.5],[0.5,0.5]])\n",
    "\n",
    "\n",
    "scale_factors = np.zeros((n_obs))\n",
    "forward_hat = np.zeros((n_obs,n_states))\n",
    "\n",
    "backward_hat = np.zeros((n_obs,n_states))\n",
    "\n",
    "init_prob = np.array([0.5,0.5])\n",
    "\n",
    "\n",
    "p_old = -10000\n",
    "tol = 0.01\n",
    "max_iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "p is:-563.4337569074765,transition is [[0.52036151 0.47963849]\n",
      " [0.51947354 0.48052646]],emission is [[0.20085356 0.79914644]\n",
      " [0.3011197  0.6988803 ]],init is [0.53333333 0.46666667]\n",
      "1\n",
      "p is:-563.4384567139621,transition is [[0.54071422 0.45928578]\n",
      " [0.53893507 0.46106493]],emission is [[0.20256486 0.79743514]\n",
      " [0.30340391 0.69659609]],init is [0.5665318 0.4334682]\n",
      "2\n",
      "p is:-563.4352708602925,transition is [[0.5610682 0.4389318]\n",
      " [0.5583987 0.4416013]],emission is [[0.20429423 0.79570577]\n",
      " [0.30575078 0.69424922]],init is [0.59944396 0.40055604]\n"
     ]
    }
   ],
   "source": [
    "for ite in range(max_iter):\n",
    "    print(ite)\n",
    "    forward_hat = np.zeros((n_obs,n_states))\n",
    "    backward_hat = np.zeros((n_obs,n_states))\n",
    "    scale_factors = np.zeros((n_obs))\n",
    "\n",
    "\n",
    "    forward_hat[0,:] = init_prob * emission[:,data[0]]\n",
    "    scale_factors[0] = np.sum(forward_hat[0,:])\n",
    "    forward_hat[0,:] = forward_hat[0,:]/scale_factors[0]\n",
    "    \n",
    "    for t in range(n_obs-1):\n",
    "        temp = np.matmul(forward_hat[t,:] ,transition) * emission[:,data[t+1]]\n",
    "        scale_factors[t+1] = np.sum(temp)\n",
    "        forward_hat[t+1,:] = temp/scale_factors[t+1]\n",
    "        # print(f'temp is {temp} and the scale factor is {scale_factors[t+1]} and the forward_hat is {forward_hat[t+1]}')\n",
    "\n",
    "\n",
    "    backward_hat[-1,:] = scale_factors[-1]\n",
    "    for t in reversed(range(n_obs-1)):\n",
    "        temp = np.matmul(backward_hat[t+1,:]*emission[:,data[t+1]],transition.T)\n",
    "        backward_hat[t,:] = temp/scale_factors[t]\n",
    "        \n",
    "\n",
    "\n",
    "    a = np.zeros((n_obs,n_states))\n",
    "    b = np.zeros((n_obs,n_states,n_states))\n",
    "    for i in range(n_obs):\n",
    "        for j in range(n_states):\n",
    "            a[i,j] = forward_hat[i,j]*backward_hat[i,j]\n",
    "        temp = np.sum(a[i,:])\n",
    "        a[i,:] = a[i,:]/temp\n",
    "\n",
    "    for t in range(n_obs-1):\n",
    "        for i in range(n_states):\n",
    "            for j in range(n_states):\n",
    "                b[t,i,j] = scale_factors[t+1]*forward_hat[t,i]*backward_hat[t+1,j]*transition[i,j]*emission[j,data[t+1]]\n",
    "\n",
    "    for i in range(n_states):\n",
    "        for j in range(n_states):\n",
    "            transition[i,j] = np.sum(b[0:-1,i,j])/np.sum(b[0:-1,i,:])\n",
    "            # print(np.sum(b[0:-1,i,j]),np.sum(b[0:-1,i,:]))\n",
    "\n",
    "    for i in range(n_states):\n",
    "        init_prob[i] = a[0,i]/np.sum(a[0,:])\n",
    "\n",
    "    for i in range(n_states):\n",
    "        for j in range(n_states):\n",
    "            emission[j,i] = np.sum(a[np.argwhere(data==i),j]) / np.sum(a[:,j])\n",
    "            \n",
    "    p = np.sum(np.log(scale_factors))\n",
    "    print(f'p is:{p},transition is {transition},emission is {emission},init is {init_prob}')\n",
    "    # print(f'transition prob is: {transition}')\n",
    "    # print(f'emission prob is:{emission}')\n",
    "    if p>p_old and p - p_old < tol:\n",
    "        break\n",
    "    p_old = p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
