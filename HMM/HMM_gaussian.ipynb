{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from scipy.special import logsumexp\n",
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[]\n",
    "line_count = 0\n",
    "with open('Rainier_Weather.csv',newline='') as file:\n",
    "    csvFile = csv.reader(file,delimiter=',')\n",
    "    for lines in csvFile:\n",
    "        if line_count>0:\n",
    "            data.append([float(a) for a in lines[1:]])\n",
    "        line_count+=1\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states = 3\n",
    "n_obs = data.shape[0]\n",
    "dim_data = data.shape[1]\n",
    "\n",
    "\n",
    "transition = np.random.normal(0, 1, size=(n_states, n_states))\n",
    "log_transition = transition - logsumexp(transition, axis=1, keepdims=True)\n",
    "\n",
    "log_emission = np.log(np.random.random((n_obs, n_states)))\n",
    "\n",
    "log_forward = np.random.rand(n_obs,n_states)\n",
    "\n",
    "log_backward = np.random.rand(n_obs,n_states)\n",
    "\n",
    "log_init_prob = np.log(np.ones(n_states)/n_states)\n",
    "\n",
    "\n",
    "p_old = -10000\n",
    "tol = 0.001\n",
    "max_iter = 100\n",
    "\n",
    "means  = np.random.normal(0, 1, size=(n_states, dim_data))\n",
    "covars = np.empty((n_states, dim_data, dim_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baum_welch(obs, states, n_iters):\n",
    "    \"\"\"EM for hidden Markov models, i.e. the Baum–Welch algorithm. Numerical \n",
    "    instability handled by working in log space.\n",
    "    \"\"\"\n",
    "    N, D = obs.shape\n",
    "    K = len(states)\n",
    "\n",
    "    # Initialize parameters \\theta:\n",
    "    #\n",
    "    # 1. Probaiblities \\pi (size K).\n",
    "    # 2. Transition probability matrix A.\n",
    "    # 3. Emission parameters \\phi (Gaussian case: \\mu and \\Sigma).\n",
    "    #\n",
    "    log_pi = np.ones(K) / K\n",
    "    assert np.isclose(log_pi.sum(), 1)\n",
    "\n",
    "    log_A  = np.random.normal(0, 1, size=(K, K))\n",
    "    log_A -= logsumexp(log_A, axis=1, keepdims=True)\n",
    "    assert np.allclose(np.sum(np.exp(log_A), axis=1), 1)\n",
    "\n",
    "    means  = np.random.normal(0, 1, size=(K, D))\n",
    "    covars = np.empty((K, D, D))\n",
    "    for k in range(K):\n",
    "        # Ensure initial covariance matrices are PSD.\n",
    "        tmp = np.random.random((D, 2*D))\n",
    "        covars[k] = tmp @ tmp.T\n",
    "\n",
    "    # Initialize emission probabilities (size N × K).\n",
    "    log_emm_prob = np.random.random((N, K))\n",
    "\n",
    "    # The n-th row is log(alpha(z_n)).\n",
    "    # The k-th column is value z_n takes.\n",
    "    # So (nk)-th cell is alpha(z_n = k).\n",
    "    log_alpha = np.zeros((N, K))\n",
    "    log_beta  = np.zeros((N, K))\n",
    "\n",
    "    for _ in range(n_iters):\n",
    "\n",
    "        # E-step (forward-backward algorithm).\n",
    "        # ------------------------------------\n",
    "        for k in range(K):\n",
    "            log_alpha[0, k] = log_pi[k] + log_emm_prob[0, k]\n",
    "\n",
    "        for n in range(1, N):\n",
    "            for k in range(K):\n",
    "                tmp = np.empty(K)\n",
    "                for j in range(K):\n",
    "                    tmp[j] = log_alpha[n-1, j] + log_A[j, k]\n",
    "                log_alpha[n, k] = logsumexp(tmp) + log_emm_prob[n, k]\n",
    "\n",
    "        log_beta[N-1] = 0  # log(1)\n",
    "        for n in reversed(range(N-1)):\n",
    "            for k in range(K):\n",
    "                tmp = np.empty(K)\n",
    "                for j in range(K):\n",
    "                    tmp[j] = (log_beta[n+1, j] \n",
    "                              + log_emm_prob[n+1, j] \n",
    "                              + log_A[k, j])\n",
    "                log_beta[n, k] = logsumexp(tmp)\n",
    "\n",
    "        # M-step.\n",
    "        # ------------------------------------\n",
    "\n",
    "        # Compute first posterior moment, \\gamma (size N × K).\n",
    "        # Eq. 13.33 in Bishop.\n",
    "        log_gamma = log_alpha + log_beta\n",
    "        log_evidence = logsumexp(log_alpha[N-1])\n",
    "        gamma = np.exp(log_gamma - log_evidence)\n",
    "        assert np.allclose(np.sum(gamma, axis=1), 1)\n",
    "\n",
    "        # Compute second posterior moment, \\xi (size N × K × K). For the n-th \n",
    "        # sample, the (K × K) matrix A is defined such that \n",
    "        # A_{ij} = E[z_{n} = i, z_{n+1} = j].\n",
    "        #\n",
    "        # Eq. 13.43 in Bishop.\n",
    "        log_xi = np.empty((N, K, K))\n",
    "        for n in range(N-1):\n",
    "            tmp = np.empty((K, K))\n",
    "            for k in range(K):\n",
    "                for j in range(K):\n",
    "                    tmp[k, j] = (log_alpha[n, k]\n",
    "                                 + log_beta[n+1, j] \n",
    "                                 + log_emm_prob[n+1, j] \n",
    "                                 + log_A[k, j]\n",
    "                                 - log_evidence)\n",
    "            log_xi[n] = tmp\n",
    "\n",
    "        # Eq. 13.18 in Bishop.\n",
    "        log_pi = log_gamma[0] - logsumexp(log_gamma[0])\n",
    "        assert log_pi.size == K\n",
    "        assert np.isclose(np.sum(np.exp(log_pi)), 1)\n",
    "\n",
    "        # Eq. 13.19 in Bishop.\n",
    "        for i in range(K):\n",
    "            for j in range(K):\n",
    "                log_A[i, j] = logsumexp(log_xi[1:, i, j]) - logsumexp(log_xi[1:, i, :])\n",
    "        assert np.allclose(np.sum(np.exp(log_A), axis=1), 1)\n",
    "\n",
    "        # Use matrix multiplication to sum over N.\n",
    "        # Eq. 13.20 in Bishop.\n",
    "        for k in range(K):\n",
    "            means[k] = obs.T @ gamma[:, k]\n",
    "            means[k] /= gamma[:, k].sum()\n",
    "\n",
    "        # Compute new covariances.\n",
    "        # Eq. 13.21 in Bishop.\n",
    "        for k in range(K):\n",
    "            covars[k] = np.zeros((D, D))\n",
    "            for n in range(N):\n",
    "                dev = obs[n] - means[k]\n",
    "                covars[k] += gamma[n, k] * np.outer(dev, dev.T)\n",
    "            covars[k] /= gamma[:, k].sum()\n",
    "\n",
    "        # Recompute emission probabilities using inferred states.\n",
    "        for n in range(N):\n",
    "            x = obs[n]\n",
    "            for k in range(K):\n",
    "                mu = means[k]\n",
    "                # var = covars[k] + 100 * np.eye(D)\n",
    "                M = np.random.random((N, D))\n",
    "                var = M.T @ M\n",
    "                log_emm_prob[n, k] = mvn.logpdf(x, mu, var)\n",
    "\n",
    "    Z = np.argmax(gamma, axis=1)\n",
    "    theta = (np.exp(log_pi), np.exp(log_A), means, covars)\n",
    "    return Z, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z,theta = baum_welch(data, [1,1,1], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ite in range(max_iter):\n",
    "\n",
    "\n",
    "    log_forward[0,i] = log_init_prob + log_emission[0,:]\n",
    "    \n",
    "    for t in range(n_obs-1):\n",
    "        log_forward[t+1,:] = np.matmul(log_forward[t,:] ,transition) + log_emission[t+1,:]\n",
    "\n",
    "    backward[-1,:] = 1\n",
    "    for t in reversed(range(size-1)):\n",
    "        temp = np.matmul(backward_hat[t+1,:]*emission[:,data[t+1]],np.transpose(transition))\n",
    "        backward[t,:] = \n",
    "\n",
    "\n",
    "    a = np.zeros((size,n_states))\n",
    "    b = np.zeros((size,n_states,n_states))\n",
    "    for i in range(size):\n",
    "        for j in range(n_states):\n",
    "            a[i,j] = forward_hat[i,j]*backward_hat[i,j]\n",
    "    for t in range(size-1):\n",
    "        for i in range(n_states):\n",
    "            for j in range(n_states):\n",
    "                b[t,i,j] = scale_factors[t+1]*forward_hat[t,i]*backward_hat[t+1,j]*transition[i,j]*emission[j,data[t+1]]\n",
    "\n",
    "    for i in range(n_states):\n",
    "        for j in range(n_states):\n",
    "            transition[i,j] = np.sum(b[0:-1,i,j])/np.sum(b[0:-1,i,:])\n",
    "\n",
    "    for i in range(n_states):\n",
    "        init_prob[i] = a[0,i]/np.sum(a[0,:])\n",
    "\n",
    "    for i in range(n_states):\n",
    "        for j in range(n_obs):\n",
    "            emission[i,j] = np.sum(a[np.argwhere(data==j),i]) / np.sum(a[:,i])\n",
    "            \n",
    "    p = np.sum(np.log(scale_factors))\n",
    "    print(f'p is:{p}')\n",
    "    print(f'transition prob is: {transition}')\n",
    "    print(f'emission prob is:{emission}')\n",
    "    # if p - p_old < tol:\n",
    "    #     break\n",
    "    p_old = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1000, 1000, 1000])\n",
    "# def logsumexp(x):\n",
    "#     # c = x.max()\n",
    "#     c = 0\n",
    "#     return c + np.log(np.sum(np.exp(x - c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(x - logsumexp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
