{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_states = 2\n",
    "\n",
    "model = hmm.CategoricalHMM(n_components=hmm_states)\n",
    "model.emissionprob_ = np.array([[0.1,0.9],[0.9,0.1]])\n",
    "model.transmat_ = np.array([[0.9,0.1],[0.1,0.9]])\n",
    "model.startprob_ = np.array([0.8,0.2])\n",
    "data,states = model.sample(n_samples = 1000,random_state=28)\n",
    "data = np.squeeze(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
      " 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 0 0 1 1 0 0 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0\n",
      " 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0\n",
      " 0 0 0 1 1 0 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 1 0 0 1 1 1 1 0 1 1 0\n",
      " 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 1 1 1 1 0\n",
      " 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 1 1 1 0 1 0 1 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# constant n_obs\n",
    "# n_obs = 1000\n",
    "# # Set p(H) apriori for simulation as a biased coin.\n",
    "# p_h = 0.8\n",
    "\n",
    "# # Model experiment as a single biased coin flipped 1000 times.\n",
    "# data = np.random.binomial(1, p_h, n_obs=n_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states = 2\n",
    "n_features = 2\n",
    "n_obs = data.shape[0]\n",
    "# emission = np.random.rand(n_obs,n_states)\n",
    "# emission = emission/np.tile(np.expand_dims(np.sum(emission,axis=1),axis=1),(1,2))\n",
    "\n",
    "emission = np.random.rand(n_states,n_features)\n",
    "emission = emission/np.tile(np.expand_dims(np.sum(emission,axis=1),axis=1),(1,2))\n",
    "# emission = np.array([[0.5,0.5],[0.5,0.5]])\n",
    "\n",
    "transition =  np.random.rand(n_states,n_states)\n",
    "transition = transition/np.tile(np.expand_dims(np.sum(transition,axis=1),axis=1),(1,2))\n",
    "transition = np.array([[0.6,0.4],[0.5,0.5]])\n",
    "\n",
    "\n",
    "forward = np.random.rand(n_obs,n_states)\n",
    "scale_factors = np.zeros((n_obs))\n",
    "forward_hat = np.zeros((n_obs,n_states))\n",
    "\n",
    "backward = np.random.rand(n_obs,n_states)\n",
    "backward_hat = np.zeros((n_obs,n_states))\n",
    "\n",
    "init_prob = np.array([0.5,0.5])\n",
    "\n",
    "\n",
    "p_old = -10000\n",
    "tol = 0.0001\n",
    "max_iter = 1\n",
    "\n",
    "mu = np.random.rand(n_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emission is [[0.51426989 0.48573011]\n",
      " [0.58570281 0.41429719]] and transition is [[0.6 0.4]\n",
      " [0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "print(f'emission is {emission} and transition is {transition}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p is:-698.6094116918578,transition is [[0.65056614 0.34943386]\n",
      " [0.5509711  0.4490289 ]],emission is [[0.45698117 0.54301883]\n",
      " [0.53658786 0.46341214]],init is [0.59860748 0.40139252]\n"
     ]
    }
   ],
   "source": [
    "for ite in range(max_iter):\n",
    "    forward_hat = np.zeros((n_obs,n_states))\n",
    "    backward_hat = np.zeros((n_obs,n_states))\n",
    "    scale_factors = np.zeros((n_obs))\n",
    "\n",
    "\n",
    "    forward[0,:] = init_prob * emission[:,data[0]]\n",
    "    scale_factors[0] = np.sum(forward[0,:])\n",
    "    forward_hat[0,:] = forward[0,:]/scale_factors[0]\n",
    "    \n",
    "    for t in range(n_obs-1):\n",
    "        temp = np.matmul(forward_hat[t,:] ,np.transpose(transition)) * emission[:,data[t+1]]\n",
    "        scale_factors[t+1] = np.sum(temp)\n",
    "        forward_hat[t+1,:] = temp/scale_factors[t+1]\n",
    "        # print(f'temp is {temp} and the scale factor is {scale_factors[t+1]} and the forward_hat is {forward_hat[t+1]}')\n",
    "\n",
    "        forward[t+1,:] = forward_hat[t+1,:]*np.prod(scale_factors[0:t+1])\n",
    "\n",
    "    backward[-1,:] = 1\n",
    "    backward_hat[-1,:] = backward[-1,:]\n",
    "    for t in reversed(range(n_obs-1)):\n",
    "        temp = np.matmul(backward_hat[t+1,:]*emission[:,data[t+1]],transition)\n",
    "        backward_hat[t,:] = temp/scale_factors[t+1]\n",
    "        backward[t,:] = backward_hat[t,:]*np.prod(scale_factors[t+1:-1])\n",
    "\n",
    "\n",
    "    a = np.zeros((n_obs,n_states))\n",
    "    b = np.zeros((n_obs,n_states,n_states))\n",
    "    for i in range(n_obs):\n",
    "        for j in range(n_states):\n",
    "            a[i,j] = forward_hat[i,j]*backward_hat[i,j]\n",
    "    for t in range(n_obs-1):\n",
    "        for i in range(n_states):\n",
    "            for j in range(n_states):\n",
    "                b[t,i,j] = scale_factors[t+1]*forward_hat[t,i]*backward_hat[t+1,j]*transition[i,j]*emission[j,data[t+1]]\n",
    "\n",
    "    for i in range(n_states):\n",
    "        for j in range(n_states):\n",
    "            transition[i,j] = np.sum(b[0:-1,i,j])/np.sum(b[0:-1,i,:])\n",
    "            # print(np.sum(b[0:-1,i,j]),np.sum(b[0:-1,i,:]))\n",
    "\n",
    "    for i in range(n_states):\n",
    "        init_prob[i] = a[0,i]/np.sum(a[0,:])\n",
    "\n",
    "    for i in range(n_states):\n",
    "        for j in range(n_states):\n",
    "            emission[j,i] = np.sum(a[np.argwhere(data==i),j]) / np.sum(a[:,j])\n",
    "            \n",
    "    p = np.sum(np.log(scale_factors))\n",
    "    print(f'p is:{p},transition is {transition},emission is {emission},init is {init_prob}')\n",
    "    # print(f'transition prob is: {transition}')\n",
    "    # print(f'emission prob is:{emission}')\n",
    "    if p>p_old and p - p_old < tol:\n",
    "        break\n",
    "    p_old = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.98713717e-38, 1.00000000e+00])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forward[0,:] = init_prob * emission[:,data[0]]\n",
    "scale_factors[0] = np.sum(forward[0,:])\n",
    "forward_hat[0,:] = forward[0,:]/scale_factors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14733892, 0.85266108])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_hat[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = hmm.CategoricalHMM(n_components=n_states,emissionprob_prior=emission,transmat_prior=transition,startprob_prior=init_prob)\n",
    "model2 = hmm.CategoricalHMM(n_components=n_states,n_iter=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most likely hidden states: [0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1\n",
      " 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "model2.fit(data.reshape(-1,1))\n",
    "hidden_states = model2.predict(data.reshape(-1,1))\n",
    "print(\"Most likely hidden states:\", hidden_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.monitor_.converged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0869828 , 0.9130172 ],\n",
       "       [0.88200582, 0.11799418]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.emissionprob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88402319, 0.11597681],\n",
       "       [0.11142172, 0.88857828]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.transmat_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
