{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# constant size\n",
    "size = 1000\n",
    "# Set p(H) apriori for simulation as a biased coin.\n",
    "p_h = 0.5\n",
    "\n",
    "# Model experiment as a single biased coin flipped 1000 times.\n",
    "data = np.random.binomial(1, p_h, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states = 2\n",
    "n_obs = 2\n",
    "\n",
    "emission = np.random.rand(size,n_states)\n",
    "emission = emission/np.tile(np.expand_dims(np.sum(emission,axis=1),axis=1),(1,2))\n",
    "\n",
    "transition = np.array([[0.1,0.9],[0.9,0.1]])\n",
    "\n",
    "\n",
    "forward = np.random.rand(size,n_states)\n",
    "scale_factors = np.zeros((size))\n",
    "forward_hat = np.zeros((size,n_states))\n",
    "\n",
    "backward = np.random.rand(size,n_states)\n",
    "backward_hat = np.zeros((size,n_states))\n",
    "\n",
    "init_prob = np.array([0.5,0.5])\n",
    "init_obs = np.zeros(n_states)\n",
    "\n",
    "p_old = -10000\n",
    "tol = 0.001\n",
    "max_iter = 100\n",
    "\n",
    "mu = np.random.rand(n_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p is:-723.0570062773961\n",
      "p is:-682.2610851822665\n",
      "p is:-693.55065126645\n",
      "p is:-693.6104625215752\n",
      "p is:-693.6703156803047\n",
      "p is:-693.7300559733178\n",
      "p is:-693.7896790503091\n",
      "p is:-693.8491806881063\n",
      "p is:-693.9085567938562\n",
      "p is:-693.9678034163218\n",
      "p is:-694.0269167567895\n",
      "p is:-694.0858931795145\n",
      "p is:-694.1447292216562\n",
      "p is:-694.2034216026457\n",
      "p is:-694.2619672329427\n",
      "p is:-694.3203632221264\n",
      "p is:-694.3786068862917\n",
      "p is:-694.4366957546965\n",
      "p is:-694.4946275756465\n",
      "p is:-694.5524003215755\n",
      "p is:-694.6100121933026\n",
      "p is:-694.6674616234537\n",
      "p is:-694.7247472790236\n",
      "p is:-694.7818680630852\n",
      "p is:-694.8388231156318\n",
      "p is:-694.8956118135636\n",
      "p is:-694.95223376982\n",
      "p is:-695.0086888316775\n",
      "p is:-695.0649770782261\n",
      "p is:-695.1210988170467\n",
      "p is:-695.1770545801207\n",
      "p is:-695.232845118996\n",
      "p is:-695.2884713992485\n",
      "p is:-695.3439345942767\n",
      "p is:-695.3992360784662\n",
      "p is:-695.4543774197723\n",
      "p is:-695.509360371763\n",
      "p is:-695.5641868651765\n",
      "p is:-695.6188589990318\n",
      "p is:-695.673379031352\n",
      "p is:-695.7277493695501\n",
      "p is:-695.7819725605268\n",
      "p is:-695.8360512805317\n",
      "p is:-695.8899883248441\n",
      "p is:-695.9437865973158\n",
      "p is:-695.9974490998366\n",
      "p is:-696.0509789217626\n",
      "p is:-696.1043792293558\n",
      "p is:-696.157653255286\n",
      "p is:-696.210804288226\n",
      "p is:-696.2638356625991\n",
      "p is:-696.3167507484968\n",
      "p is:-696.3695529418196\n",
      "p is:-696.4222456546635\n",
      "p is:-696.474832305987\n",
      "p is:-696.5273163125858\n",
      "p is:-696.5797010803976\n",
      "p is:-696.6319899961629\n",
      "p is:-696.6841864194541\n",
      "p is:-696.7362936750942\n",
      "p is:-696.7883150459726\n",
      "p is:-696.8402537662785\n",
      "p is:-696.8921130151413\n",
      "p is:-696.9438959107028\n",
      "p is:-696.9956055046077\n",
      "p is:-697.0472447769205\n",
      "p is:-697.0988166314654\n",
      "p is:-697.1503238915766\n",
      "p is:-697.201769296272\n",
      "p is:-697.2531554968131\n",
      "p is:-697.3044850536734\n",
      "p is:-697.3557604338728\n",
      "p is:-697.4069840086931\n",
      "p is:-697.4581580517407\n",
      "p is:-697.5092847373492\n",
      "p is:-697.5603661393122\n",
      "p is:-697.6114042299164\n",
      "p is:-697.6624008792742\n",
      "p is:-697.71335785492\n",
      "p is:-697.7642768216781\n",
      "p is:-697.8151593417571\n",
      "p is:-697.8660068750733\n",
      "p is:-697.916820779777\n",
      "p is:-697.9676023129718\n",
      "p is:-698.0183526315966\n",
      "p is:-698.069072793472\n",
      "p is:-698.1197637584796\n",
      "p is:-698.1704263898732\n",
      "p is:-698.2210614556902\n",
      "p is:-698.27166963027\n",
      "p is:-698.3222514958466\n",
      "p is:-698.372807544218\n",
      "p is:-698.4233381784711\n",
      "p is:-698.4738437147575\n",
      "p is:-698.5243243841055\n",
      "p is:-698.5747803342617\n",
      "p is:-698.6252116315534\n",
      "p is:-698.6756182627673\n",
      "p is:-698.7260001370273\n",
      "p is:-698.7763570876771\n"
     ]
    }
   ],
   "source": [
    "for ite in range(max_iter):\n",
    "    forward[0,:] = init_prob * emission[0,:]\n",
    "    scale_factors[0] = np.sum(forward[0,:])\n",
    "    forward_hat[0,:] = forward[0,:]/scale_factors[0]\n",
    "    \n",
    "    for t in range(size-1):\n",
    "        temp = np.matmul(forward_hat[t,:] ,transition) * emission[t+1,:]\n",
    "        scale_factors[t+1] = np.sum(temp)\n",
    "        forward_hat[t+1,:] = temp/scale_factors[t+1]\n",
    "        forward[t+1,:] = forward_hat[t+1,:]*np.prod(scale_factors[0:t+1])\n",
    "\n",
    "    backward[-1,:] = 1\n",
    "    backward_hat[-1,:] = backward[-1,:]\n",
    "    for t in reversed(range(size-1)):\n",
    "        temp = np.matmul(backward_hat[t+1,:]*emission[t+1,:],np.transpose(transition))\n",
    "        backward_hat[t,:] = temp/scale_factors[t+1]\n",
    "        backward[t,:] = backward_hat[t,:]*np.prod(scale_factors[t+1:-1])\n",
    "\n",
    "\n",
    "    a = np.zeros((size,n_states))\n",
    "    b = np.zeros((size,n_states,n_states))\n",
    "    for i in range(size):\n",
    "        for j in range(n_states):\n",
    "            a[i,j] = forward_hat[i,j]*backward_hat[i,j]\n",
    "    for t in range(size-1):\n",
    "        for i in range(n_states):\n",
    "            for j in range(n_states):\n",
    "                b[t,i,j] = scale_factors[t+1]*forward_hat[t,i]*backward_hat[t+1,j]*transition[i,j]*emission[j,data[t+1]]\n",
    "\n",
    "    for i in range(n_states):\n",
    "        for j in range(n_states):\n",
    "            transition[i,j] = np.sum(b[0:-1,i,j])/np.sum(b[0:-1,i,:])\n",
    "\n",
    "    for i in range(n_states):\n",
    "        init_prob[i] = a[0,i]/np.sum(a[0,:])\n",
    "\n",
    "\n",
    "    for j in range(n_states):\n",
    "        emission[:,j] = np.sum(a[np.argwhere(data==j),j]) / np.sum(a[:,j])\n",
    "            \n",
    "    p = np.sum(np.log(scale_factors))\n",
    "    print(f'p is:{p}')\n",
    "    # print(f'transition prob is: {transition}')\n",
    "    # print(f'emission prob is:{emission}')\n",
    "    # if p - p_old < tol:\n",
    "    #     break\n",
    "    p_old = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35334018, 0.64665982],\n",
       "       [0.96868785, 0.03131215]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08398874, 0.91601126])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
