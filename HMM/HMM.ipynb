{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# constant size\n",
    "size = 1000\n",
    "# Set p(H) apriori for simulation as a biased coin.\n",
    "p_h = 0.1\n",
    "\n",
    "# Model experiment as a single biased coin flipped 1000 times.\n",
    "data = np.random.binomial(1, p_h, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states = 2\n",
    "n_obs = 2\n",
    "\n",
    "# emission = np.random.rand(size,n_states)\n",
    "# emission = emission/np.tile(np.expand_dims(np.sum(emission,axis=1),axis=1),(1,2))\n",
    "\n",
    "emission = np.random.rand(n_states,n_obs)\n",
    "emission = emission/np.tile(np.expand_dims(np.sum(emission,axis=1),axis=1),(1,2))\n",
    "# emission = np.array([[0.5,0.5],[0.5,0.5]])\n",
    "\n",
    "transition =  np.random.rand(n_states,n_states)\n",
    "transition = transition/np.tile(np.expand_dims(np.sum(transition,axis=1),axis=1),(1,2))\n",
    "# transition = np.array([[0.3,0.7],[0.4,0.6]])\n",
    "\n",
    "\n",
    "forward = np.random.rand(size,n_states)\n",
    "scale_factors = np.zeros((size))\n",
    "forward_hat = np.zeros((size,n_states))\n",
    "\n",
    "backward = np.random.rand(size,n_states)\n",
    "backward_hat = np.zeros((size,n_states))\n",
    "\n",
    "init_prob = np.array([0.5,0.5])\n",
    "\n",
    "\n",
    "p_old = -10000\n",
    "tol = 0.0001\n",
    "max_iter = 100\n",
    "\n",
    "mu = np.random.rand(n_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p is:-791.4319589098212\n",
      "p is:-370.77003624631516\n",
      "p is:-371.28257877649594\n",
      "p is:-371.3675081969816\n",
      "p is:-371.3910534647555\n",
      "p is:-371.3447567452826\n",
      "p is:-371.24074556287707\n",
      "p is:-371.11821586134295\n",
      "p is:-371.0164515588318\n",
      "p is:-370.9512477622775\n",
      "p is:-370.91695095946\n",
      "p is:-370.90132398087235\n",
      "p is:-370.8948778238349\n",
      "p is:-370.892391791559\n",
      "p is:-370.8914772381577\n",
      "p is:-370.89115356689524\n",
      "p is:-370.89104384947143\n",
      "p is:-370.8910091233908\n",
      "p is:-370.8909996639876\n",
      "p is:-370.89099816446867\n",
      "p is:-370.89099881862876\n",
      "p is:-370.89099980342144\n",
      "p is:-370.891000628268\n",
      "p is:-370.8910012200323\n",
      "p is:-370.8910016174526\n",
      "p is:-370.89100187552555\n",
      "p is:-370.89100203995326\n",
      "p is:-370.8910021435027\n",
      "p is:-370.891002208214\n",
      "p is:-370.89100224843463\n",
      "p is:-370.8910022733305\n",
      "p is:-370.8910022886904\n",
      "p is:-370.8910022981409\n",
      "p is:-370.89100230394183\n",
      "p is:-370.8910023074945\n",
      "p is:-370.8910023096664\n",
      "p is:-370.89100231099223\n",
      "p is:-370.8910023117995\n",
      "p is:-370.89100231229094\n",
      "p is:-370.8910023125894\n",
      "p is:-370.89100231277024\n",
      "p is:-370.89100231288006\n",
      "p is:-370.89100231294606\n",
      "p is:-370.8910023129864\n",
      "p is:-370.8910023130107\n",
      "p is:-370.8910023130252\n",
      "p is:-370.8910023130339\n",
      "p is:-370.8910023130393\n",
      "p is:-370.89100231304246\n",
      "p is:-370.8910023130443\n",
      "p is:-370.89100231304593\n",
      "p is:-370.8910023130461\n",
      "p is:-370.8910023130466\n",
      "p is:-370.8910023130469\n",
      "p is:-370.89100231304695\n",
      "p is:-370.891002313047\n",
      "p is:-370.891002313047\n",
      "p is:-370.89100231304724\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.8910023130473\n",
      "p is:-370.8910023130471\n",
      "p is:-370.89100231304724\n",
      "p is:-370.89100231304724\n",
      "p is:-370.89100231304747\n",
      "p is:-370.8910023130474\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.8910023130472\n",
      "p is:-370.89100231304747\n",
      "p is:-370.89100231304707\n",
      "p is:-370.8910023130472\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n",
      "p is:-370.89100231304735\n"
     ]
    }
   ],
   "source": [
    "for ite in range(max_iter):\n",
    "    forward[0,:] = init_prob * emission[:,data[0]]\n",
    "    scale_factors[0] = np.sum(forward[0,:])\n",
    "    forward_hat[0,:] = forward[0,:]/scale_factors[0]\n",
    "    \n",
    "    for t in range(size-1):\n",
    "        temp = np.matmul(forward_hat[t,:] ,transition) * emission[:,data[t+1]]\n",
    "        scale_factors[t+1] = np.sum(temp)\n",
    "        forward_hat[t+1,:] = temp/scale_factors[t+1]\n",
    "        forward[t+1,:] = forward_hat[t+1,:]*np.prod(scale_factors[0:t+1])\n",
    "\n",
    "    backward[-1,:] = 1\n",
    "    backward_hat[-1,:] = backward[-1,:]\n",
    "    for t in reversed(range(size-1)):\n",
    "        temp = np.matmul(backward_hat[t+1,:]*emission[:,data[t+1]],np.transpose(transition))\n",
    "        backward_hat[t,:] = temp/scale_factors[t+1]\n",
    "        backward[t,:] = backward_hat[t,:]*np.prod(scale_factors[t+1:-1])\n",
    "\n",
    "\n",
    "    a = np.zeros((size,n_states))\n",
    "    b = np.zeros((size,n_states,n_states))\n",
    "    for i in range(size):\n",
    "        for j in range(n_states):\n",
    "            a[i,j] = forward_hat[i,j]*backward_hat[i,j]\n",
    "    for t in range(size-1):\n",
    "        for i in range(n_states):\n",
    "            for j in range(n_states):\n",
    "                b[t,i,j] = scale_factors[t+1]*forward_hat[t,i]*backward_hat[t+1,j]*transition[i,j]*emission[j,data[t+1]]\n",
    "\n",
    "    for i in range(n_states):\n",
    "        for j in range(n_states):\n",
    "            transition[i,j] = np.sum(b[0:-1,i,j])/np.sum(b[0:-1,i,:])\n",
    "\n",
    "    for i in range(n_states):\n",
    "        init_prob[i] = a[0,i]/np.sum(a[0,:])\n",
    "\n",
    "    for i in range(n_states):\n",
    "        for j in range(n_states):\n",
    "            emission[j,i] = np.sum(a[np.argwhere(data==i),j]) / np.sum(a[:,j])\n",
    "            \n",
    "    p = np.sum(np.log(scale_factors))\n",
    "    print(f'p is:{p}')\n",
    "    # print(f'transition prob is: {transition}')\n",
    "    # print(f'emission prob is:{emission}')\n",
    "    # if p - p_old < tol:\n",
    "    #     break\n",
    "    p_old = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49962351, 0.50037649],\n",
       "       [0.878     , 0.122     ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.76081113e-24, 1.00000000e+00],\n",
       "       [1.77044837e-23, 1.00000000e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hmm.CategoricalHMM(n_components=n_states,emissionprob_prior=emission,transmat_prior=transition,startprob_prior=init_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watson/.local/lib/python3.10/site-packages/hmmlearn/utils.py:55: RuntimeWarning: invalid value encountered in subtract\n",
      "  a -= a_lse\n",
      "Model is not converging.  Current: -inf is not greater than -429.3354678472401. Delta is -inf\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "startprob_ must sum to 1 (got nan)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(data\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMost likely hidden states:\u001b[39m\u001b[38;5;124m\"\u001b[39m, hidden_states)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hmmlearn/_emissions.py:27\u001b[0m, in \u001b[0;36m_make_wrapper.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_wrapper\u001b[39m(func):\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m functools\u001b[38;5;241m.\u001b[39mwraps(func)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hmmlearn/base.py:375\u001b[0m, in \u001b[0;36m_AbstractHMM.predict\u001b[0;34m(self, X, lengths)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, lengths\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03m    Find most likely state sequence corresponding to ``X``.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m        Labels for each sample from ``X``.\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m     _, state_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m state_sequence\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hmmlearn/_emissions.py:27\u001b[0m, in \u001b[0;36m_make_wrapper.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_wrapper\u001b[39m(func):\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m functools\u001b[38;5;241m.\u001b[39mwraps(func)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hmmlearn/base.py:336\u001b[0m, in \u001b[0;36m_AbstractHMM.decode\u001b[0;34m(self, X, lengths, algorithm)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;124;03mFind most likely state sequence corresponding to ``X``.\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03mscore : Compute the log probability under the model.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    335\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstartprob_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m algorithm \u001b[38;5;241m=\u001b[39m algorithm \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m algorithm \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m DECODER_ALGORITHMS:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hmmlearn/hmm.py:139\u001b[0m, in \u001b[0;36mCategoricalHMM._check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memissionprob_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_2d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memissionprob_)\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hmmlearn/base.py:971\u001b[0m, in \u001b[0;36mBaseHMM._check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstartprob_) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components:\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstartprob_ must have length n_components\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 971\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_sum_1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstartprob_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransmat_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransmat_)\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransmat_\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hmmlearn/base.py:951\u001b[0m, in \u001b[0;36mBaseHMM._check_sum_1\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    949\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(s, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    952\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must sum to 1 (got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m s\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    954\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows must sum to 1 (got row sums of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m s\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    956\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 1D or 2D array\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: startprob_ must sum to 1 (got nan)"
     ]
    }
   ],
   "source": [
    "model.fit(data.reshape(-1,1))\n",
    "hidden_states = model.predict(data.reshape(-1,1))\n",
    "print(\"Most likely hidden states:\", hidden_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.emissionprob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transmat_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
