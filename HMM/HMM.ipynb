{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_states = 2\n",
    "\n",
    "model = hmm.CategoricalHMM(n_components=hmm_states)\n",
    "model.emissionprob_ = np.array([[0.4,0.6],[0.3,0.7]])\n",
    "model.transmat_ = np.array([[0.2,0.8],[0.1,0.9]])\n",
    "model.startprob_ = np.array([0.4,0.6])\n",
    "data,states = model.sample(n_samples = 1000,random_state=28)\n",
    "data = np.squeeze(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# constant n_obs\n",
    "# n_obs = 1000\n",
    "# # Set p(H) apriori for simulation as a biased coin.\n",
    "# p_h = 0.8\n",
    "\n",
    "# # Model experiment as a single biased coin flipped 1000 times.\n",
    "# data = np.random.binomial(1, p_h, n_obs=n_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states = 2\n",
    "n_features = 2\n",
    "n_obs = data.shape[0]\n",
    "# emission = np.random.rand(n_obs,n_states)\n",
    "# emission = emission/np.tile(np.expand_dims(np.sum(emission,axis=1),axis=1),(1,2))\n",
    "\n",
    "emission = np.random.rand(n_states,n_features)\n",
    "emission = emission/np.tile(np.expand_dims(np.sum(emission,axis=1),axis=1),(1,2))\n",
    "# emission = np.array([[0.5,0.5],[0.5,0.5]])\n",
    "\n",
    "transition =  np.random.rand(n_states,n_states)\n",
    "transition = transition/np.tile(np.expand_dims(np.sum(transition,axis=1),axis=1),(1,2))\n",
    "# transition = np.array([[0.6,0.4],[0.5,0.5]])\n",
    "\n",
    "\n",
    "# forward = np.random.rand(n_obs,n_states)\n",
    "scale_factors = np.zeros((n_obs))\n",
    "forward_hat = np.zeros((n_obs,n_states))\n",
    "\n",
    "# backward = np.random.rand(n_obs,n_states)\n",
    "backward_hat = np.zeros((n_obs,n_states))\n",
    "\n",
    "init_prob = np.array([0.5,0.5])\n",
    "\n",
    "\n",
    "p_old = -10000\n",
    "tol = 0.01\n",
    "max_iter = 100\n",
    "\n",
    "mu = np.random.rand(n_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emission is [[0.48392847 0.51607153]\n",
      " [0.94652593 0.05347407]] and transition is [[0.47933558 0.52066442]\n",
      " [0.43619813 0.56380187]]\n"
     ]
    }
   ],
   "source": [
    "print(f'emission is {emission} and transition is {transition}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p is: -998.4918484902878\n",
      "p is: -638.5302220805\n",
      "p is: -624.2442218326438\n",
      "p is: -630.900873109427\n",
      "p is: -632.1213967987817\n",
      "p is: -629.0405237669353\n",
      "p is: -625.2973067536612\n",
      "p is: -623.3015535659624\n",
      "p is: -622.5952982189926\n",
      "p is: -622.3713974104254\n",
      "p is: -622.2985412641015\n",
      "p is: -622.2742139379113\n",
      "p is: -622.2662253520143\n"
     ]
    }
   ],
   "source": [
    "for ite in range(max_iter):\n",
    "    forward_hat = np.zeros((n_obs,n_states))\n",
    "    backward_hat = np.zeros((n_obs,n_states))\n",
    "    scale_factors = np.zeros((n_obs))\n",
    "\n",
    "    for i in range(n_states):\n",
    "        forward_hat[0,i] = init_prob[i] * emission[i,data[0]]\n",
    "    scale_factors[0] = np.sum(forward_hat[0,:])\n",
    "    forward_hat[0,:] = forward_hat[0,:]/scale_factors[0]\n",
    "    \n",
    "    for t in range(1,n_obs):\n",
    "        for i in range(n_states):\n",
    "            for j in range(n_states):\n",
    "                forward_hat[t,i] += forward_hat[t-1,j] * transition[j,i]\n",
    "                # temp = np.matmul(forward_hat[t,i] ,np.transpose(transition[i,j])) * emission[i,data[t+1]]\n",
    "            forward_hat[t,i] = forward_hat[t,i] * emission[i,data[t]]\n",
    "        scale_factors[t] = np.sum(forward_hat[t,:])\n",
    "\n",
    "        forward_hat[t,:] = forward_hat[t,:]/scale_factors[t]\n",
    "        # print(f'temp is {temp} and the scale factor is {scale_factors[t+1]} and the forward_hat is {forward_hat[t+1]}')\n",
    "\n",
    "        # forward[t,i] = forward_hat[t,:]*np.prod(scale_factors[0:t])\n",
    "\n",
    "    backward_hat[-1,:] = scale_factors[-1]\n",
    "    for t in reversed(range(n_obs-1)):\n",
    "        for i in range(n_states):\n",
    "            for j in range(n_states):\n",
    "                backward_hat[t,i] += backward_hat[t+1,j] * emission[j,data[t+1]] * transition[i,j]\n",
    "        backward_hat[t,:] = backward_hat[t,:]/scale_factors[t]\n",
    "\n",
    "\n",
    "    a = np.zeros((n_obs,n_states))\n",
    "    b = np.zeros((n_obs,n_states,n_states))\n",
    "    for i in range(n_obs):\n",
    "        for j in range(n_states):\n",
    "            a[i,j] = forward_hat[i,j]*backward_hat[i,j]\n",
    "        temp = np.sum(a[i,:])\n",
    "        a[i,:] = a[i,:]/temp\n",
    "    for t in range(n_obs-1):\n",
    "        for i in range(n_states):\n",
    "            for j in range(n_states):\n",
    "                b[t,i,j] = scale_factors[t+1]*forward_hat[t,i]*backward_hat[t+1,j]*transition[i,j]*emission[j,data[t+1]]\n",
    "\n",
    "    for i in range(n_states):\n",
    "        for j in range(n_states):\n",
    "            transition[i,j] = np.sum(b[0:-1,i,j])/np.sum(b[0:-1,i,:])\n",
    "            # print(np.sum(b[0:-1,i,j]),np.sum(b[0:-1,i,:]))\n",
    "\n",
    "\n",
    "    init_prob = a[0,:]\n",
    "\n",
    "    for i in range(n_states):\n",
    "        for j in range(n_states):\n",
    "            emission[j,i] = np.sum(a[np.argwhere(data==i),j]) / np.sum(a[:,j])\n",
    "            \n",
    "    p = np.sum(np.log(scale_factors))\n",
    "    # print(f'p is:{p},transition is {transition},emission is {emission},init is {init_prob}')\n",
    "    print(f'p is: {p}')\n",
    "    # print(f'transition prob is: {transition}')\n",
    "    # print(f'emission prob is:{emission}')\n",
    "    if p>p_old and p - p_old < tol:\n",
    "        break\n",
    "    p_old = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transition is [[0.99719223 0.00280777]\n",
      " [0.99746015 0.00253985]], emission is [[0.31134945 0.68865055]\n",
      " [0.89505096 0.10494904]],init_prob is [9.99999999e-01 6.50998438e-10]\n"
     ]
    }
   ],
   "source": [
    "print(f'transition is {transition}, emission is {emission},init_prob is {init_prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = hmm.CategoricalHMM(n_components=n_states,emissionprob_prior=emission,transmat_prior=transition,startprob_prior=init_prob)\n",
    "# model2 = hmm.CategoricalHMM(n_components=hmm_states,n_iter=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.fit(data.reshape(-1,1))\n",
    "# hidden_states = model2.predict(data.reshape(-1,1))\n",
    "# print(\"Most likely hidden states:\", hidden_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.monitor_.converged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.emissionprob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.transmat_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
