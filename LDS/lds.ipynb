{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class timeVaryingLDS(object):\n",
    "    def __init__(self,T=None, transition_con = None, emission = None, Q = None, R = None, u0 = None, V0 = None, y=None):\n",
    "        \n",
    "        self.y = y # T x N\n",
    "        self.M = transition_con.shape[1] # dimension of hidden continuous states\n",
    "        self.T = T # number of observations\n",
    "        self.N = self.y.shape[1] # dimension of the observations\n",
    "        \n",
    "        self.C = emission # the emission probability of the continuous variable, T x N x M\n",
    "        self.A = transition_con # the continuous variable transition probability matrix, T x M x M \n",
    "        \n",
    "        self.Q = Q # Q is the covariance matrix of noise term added to the hidden continuous state transition, T x M x M\n",
    "        self.R = R # R is the covariance matrix of noise term added to the emission, T x N x N\n",
    "        \n",
    "        self.u0 = u0 # u0 is the initial estimate of the mean of x1, M x 1\n",
    "        self.V0 = V0 # V0 is the initial estimate of the variance of x1, M x M\n",
    "\n",
    "        self.P = np.zeros((self.T, self.M, self.M))\n",
    "        self.P[:,:,:,] = np.eye(self.M)  # P is an intermediate variable during inference, T x M x M\n",
    "        self.u = np.zeros((self.T, self.M)) # T x M x 1\n",
    "        self.V = np.zeros((self.T, self.M, self.M)) # T x M x M\n",
    "        self.K = np.zeros((self.T, self.M, self.N)) # T x M x N\n",
    "        self.c = np.zeros((self.T)) # T x 1\n",
    "\n",
    "        # for backward passing\n",
    "        self.u_hat = np.zeros((self.T, self.M)) # T x M x 1\n",
    "        self.V_hat = np.zeros((self.T, self.M, self.M)) # T x M x M\n",
    "        self.J = np.zeros((self.T, self.M, self.M)) # T x M x M\n",
    "\n",
    "\n",
    "    \n",
    "    def kalman_filtering(self):\n",
    "        S_temp = np.matmul(np.matmul(self.C[0], self.V0), self.C[0].T) + self.R[0]\n",
    "        Q_temp = np.matmul(self.C[0], self.u0)\n",
    "        I = np.eye(self.M)\n",
    "        \n",
    "        self.V[0] = np.matmul((I - np.matmul(np.matmul(np.matmul(self.V0, self.C[0].T), np.linalg.inv(S_temp)), self.C[0])), self.V0)\n",
    "        self.P[0] = np.matmul(np.matmul(self.A[0], self.V[0]), self.A[0].T) + self.Q[0]\n",
    "        self.K[0] = np.matmul(np.matmul(self.P[0], self.C[0].T), np.linalg.inv(np.matmul(np.matmul(self.C[0], self.P[0]), self.C[0].T) + self.R[0]))\n",
    "        self.u[0] = self.u0 + np.matmul(self.K[0], self.y[0] - Q_temp)\n",
    "\n",
    "        self.c[0] = multivariate_normal.pdf(self.y[0], Q_temp, S_temp)\n",
    "\n",
    "        for i in range(1,self.T,1):\n",
    "            I = np.eye(self.M)\n",
    "            Q_temp = np.matmul(np.matmul(self.C[i], self.A[i]), self.u[i-1])\n",
    "            \n",
    "            self.V[i] = np.matmul((I - np.matmul(self.K[i-1], self.C[i])), self.P[i-1])\n",
    "            self.P[i] = np.matmul(np.matmul(self.A[i], self.V[i]), self.A[i].T) + self.Q[i]\n",
    "            S_temp = np.matmul(np.matmul(self.C[i], self.P[i]), self.C[i].T) + self.R[i]\n",
    "            # print('C[i] is',self.C[i],'R[i] is',self.R[i],'A[i] is',self.A[i],'Q[i] is',self.Q[i],'P[i] is',self.P[i],'V[i] is',self.V[i])\n",
    "            self.K[i] = np.matmul(np.matmul(self.P[i], self.C[i].T), np.linalg.inv(S_temp))\n",
    "\n",
    "            self.u[i] = np.matmul(self.A[i], self.u[i-1]) + np.matmul(self.K[i-1], self.y[i] - Q_temp)\n",
    "            # print('i is:',i,'s_temp is:',S_temp)\n",
    "            self.c[i] = multivariate_normal.pdf(self.y[i], Q_temp, S_temp)\n",
    "\n",
    "    def kalman_smoothing(self):\n",
    "\n",
    "        self.u_hat[-1] = self.u[-1]\n",
    "        self.V_hat[-1] = self.V[-1]\n",
    "\n",
    "        for i in range(self.T-2,-1,-1):\n",
    "            # print(i,self.V[i],self.A[i].T,self.P[i])\n",
    "            self.J[i] = np.matmul(np.matmul(self.V[i], self.A[i].T), np.linalg.inv(self.P[i]))\n",
    "            self.u_hat[i] = self.u[i] + np.matmul(self.J[i], self.u_hat[i+1] - np.matmul(self.A[i], self.u[i]))\n",
    "            self.V_hat[i] = self.V[i] + np.matmul(np.matmul(self.J[i], self.V_hat[i+1] - self.P[i]), self.J[i].T)\n",
    "    \n",
    "    def kalman_learning(self):\n",
    "        self.u0 = self.u_hat[0]\n",
    "        self.V0 = self.V_hat[0] + np.outer(self.u_hat[0], self.u_hat[0].T) - np.outer(self.u_hat[0], self.u_hat[0].T)\n",
    "\n",
    "        # E[z[n]] : M x 1\n",
    "        # E[z[n]z[n-1].T] : M x M\n",
    "        # E[z[n]z[n].T] : M x M\n",
    "\n",
    "        self.XtXt_1 = np.zeros((self.T,self.M,self.M))\n",
    "        self.XtXt = np.zeros((self.T,self.M,self.M))\n",
    "        self.Xt_1Xt = np.zeros((self.T,self.M,self.M))\n",
    "\n",
    "        self.YtXt = np.zeros((self.T,self.N,self.M))\n",
    "        self.YtYt = np.zeros((self.T,self.N,self.N))\n",
    "        self.XtYt = np.zeros((self.T,self.M,self.N))\n",
    "        \n",
    "        self.XtXt[0] += self.V_hat[0] + np.outer(self.u_hat[0], self.u_hat[0].T)\n",
    "        \n",
    "        for i in range(1,self.T,1):\n",
    "            \n",
    "            self.XtXt_1[i] = np.matmul(self.V_hat[i],self.J[i-1].T) + np.outer(self.u_hat[i],self.u_hat[i-1].T) # z[n]z[n-1]\n",
    "            \n",
    "            self.XtXt[i] = self.V_hat[i] + np.outer(self.u_hat[i], self.u_hat[i].T) # z[n]z[n]\n",
    "            self.Xt_1Xt[i] = (np.matmul(self.V_hat[i],self.J[i-1].T) + np.outer(self.u_hat[i],self.u_hat[i-1].T)).T #z[n-1]z[n]\n",
    "\n",
    "        for i in range(self.T):\n",
    "            self.YtXt[i] = np.outer(self.y[i], self.u_hat[i].T) # y[n] * E[x[n]].T\n",
    "            self.YtYt[i] = np.outer(self.y[i], self.y[i].T) # y[n]y[n]\n",
    "            self.XtYt[i] = np.outer(self.u_hat[i], self.y[i].T) #E[x[n]] * y[n].T \n",
    "\n",
    "        sub_1 = np.sum(self.XtXt_1[1:self.T], axis=0)\n",
    "        sub_2 = np.sum(self.XtXt[0:self.T-1], axis=0)\n",
    "        sub_3 = np.sum(self.XtXt[1:self.T], axis=0)\n",
    "        sub_4 = np.sum(self.Xt_1Xt[1:self.T], axis=0)\n",
    "\n",
    "        sub_5 = np.sum(self.YtXt, axis=0)\n",
    "        sub_6 = np.sum(self.XtXt, axis=0)\n",
    "        sub_7 = np.sum(self.YtYt, axis=0)\n",
    "        sub_8 = np.sum(self.XtYt, axis=0)\n",
    "\n",
    "        self.A = np.matmul(sub_1, np.linalg.inv(sub_2))\n",
    "\n",
    "        self.Q = 1/(self.T-1) * (sub_3 - np.matmul(self.A,sub_4) - np.matmul(sub_1,self.A.T) + np.matmul(np.matmul(self.A,sub_2),self.A.T))\n",
    "        \n",
    "        self.C = np.matmul(sub_5, np.linalg.inv(sub_6))\n",
    "        self.R = 1/self.T * (sub_7 - np.matmul(self.C,sub_8) - np.matmul(sub_5,self.C.T) + np.matmul(np.matmul(self.C,sub_6),self.C.T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class KalmanFilter(object):\n",
    "#     def __init__(self, A = None, C = None, Gamma = None, Sigma = None, P = None, u0 = None, V0 = None,x=None,T=None):\n",
    "\n",
    "#         if(A is None or C is None):\n",
    "#             raise ValueError(\"Set proper system dynamics.\")\n",
    "\n",
    "#         self.x = x # T x N\n",
    "#         self.M = A.shape[0] # dimension of hidden states\n",
    "#         self.T = T # number of observations\n",
    "#         self.N = self.x.shape[1] # number of features of the observations\n",
    "\n",
    "#         self.A = A # A is the transition probability matrix, M x M \n",
    "#         self.C = C # C is the emission probability matrix, N x M\n",
    "        \n",
    "#         self.Gamma = np.eye(self.M) if Gamma is None else Gamma # Gamma is the covariance matrix of noise term added to the hidden state transition, M x M\n",
    "#         self.Sigma = np.eye(self.N) if Sigma is None else Sigma # Sigma is the covariance matrix of noise term added to the emission, N x N\n",
    "        \n",
    "#         self.P = np.zeros((self.T, self.M, self.M))\n",
    "#         self.P[:,:,] = np.eye(self.M) if P is None else P # P is an intermediate variable during inference, N x M x M\n",
    "#         self.u = np.zeros((self.T, self.M)) # T x M x 1\n",
    "#         self.V = np.zeros((self.T, self.M, self.M)) # T x M x M\n",
    "#         self.K = np.zeros((self.T, self.M, self.N)) # T x M x N\n",
    "#         self.c = np.zeros((self.T)) # T x 1\n",
    "\n",
    "#         # for backward passing\n",
    "#         self.u_hat = np.zeros((self.T, self.M)) # T x M x 1\n",
    "#         self.V_hat = np.zeros((self.T, self.M, self.M)) # T x M x M\n",
    "#         self.J = np.zeros((self.T, self.M, self.M)) # T x M x M\n",
    "\n",
    "#         self.u0 = u0 # u0 is the initial estimate of the mean of z1, M x 1\n",
    "#         self.V0 = V0 # V0 is the initial estimate of the variance of z1, M x M\n",
    "        \n",
    "#         S_temp = np.matmul(np.matmul(self.C, self.V0), self.C.T) + self.Sigma\n",
    "#         Q_temp = np.matmul(self.C, self.u0)\n",
    "#         I = np.eye(self.M)\n",
    "\n",
    "#         self.V[0] = np.matmul((I - np.matmul(np.matmul(np.matmul(self.V0, self.C.T), np.linalg.inv(S_temp)), self.C)), self.V0)\n",
    "#         self.P[0] = np.matmul(np.matmul(self.A, self.V[0]), self.A.T) + self.Gamma\n",
    "#         self.K[0] = np.matmul(np.matmul(self.P[0], self.C.T), np.linalg.inv(np.matmul(np.matmul(self.C, self.P[0]), self.C.T) + self.Sigma))\n",
    "        \n",
    "#         self.u[0] = self.u0 + np.matmul(self.K[0], self.x[0] - Q_temp)\n",
    "#         # print(self.u0,self.u[0],self.P[0],self.K[0],self.V[0])\n",
    "#         self.c[0] = multivariate_normal.pdf(self.x[0], Q_temp, S_temp)\n",
    "    \n",
    "#     def forward(self,i):\n",
    "#         # during inference, u[n], V[n], c[n] are calculated\n",
    "        \n",
    "#         # if i < self.T:\n",
    "#         I = np.eye(self.M)\n",
    "#         Q_temp = np.matmul(np.matmul(self.C, self.A), self.u[i-1])\n",
    "        \n",
    "#         self.V[i] = np.matmul((I - np.matmul(self.K[i-1], self.C)), self.P[i-1])\n",
    "#         self.P[i] = np.matmul(np.matmul(self.A, self.V[i]), self.A.T) + self.Gamma\n",
    "#         S_temp = np.matmul(np.matmul(self.C, self.P[i]), self.C.T) + self.Sigma\n",
    "\n",
    "#         self.K[i] = np.matmul(np.matmul(self.P[i], self.C.T), np.linalg.inv(S_temp))\n",
    "\n",
    "#         self.u[i] = np.matmul(self.A, self.u[i-1]) + np.matmul(self.K[i-1], self.x[i] - Q_temp)\n",
    "#         # print(f'The covariance matrix is: {S}')\n",
    "#         # print(f'The Sigma is {self.Sigma}, The Gamma is {self.Gamma}')\n",
    "#         # print(f'The A is {self.A}, The C is {self.C}, and P[{i-1}] is {self.P[i-1]}, K[{i}] is {self.K[i]}],V[{i-1}] is {self.V[i-1]}]')\n",
    "\n",
    "#         self.c[i] = multivariate_normal.pdf(self.x[i], Q_temp, S_temp)\n",
    "\n",
    "#     def backward(self,i):\n",
    "#         self.J[i] = np.matmul(np.matmul(self.V[i], self.A.T), np.linalg.inv(self.P[i]))\n",
    "#         self.u_hat[i] = self.u[i] + np.matmul(self.J[i], self.u_hat[i+1] - np.matmul(self.A, self.u[i]))\n",
    "#         self.V_hat[i] = self.V[i] + np.matmul(np.matmul(self.J[i], self.V_hat[i+1] - self.P[i]), self.J[i].T)\n",
    "    \n",
    "#     def learning(self,M,N):\n",
    "#         self.u0 = self.u_hat[0]\n",
    "#         self.V0 = self.V_hat[0] + np.outer(self.u_hat[0], self.u_hat[0].T) - np.outer(self.u_hat[0], self.u_hat[0].T)\n",
    "\n",
    "#         # E[z[n]] : M x 1\n",
    "#         # E[z[n]z[n-1].T] : M x M\n",
    "#         # E[z[n]z[n].T] : M x M\n",
    "\n",
    "#         sub_1 = np.zeros((M,M))\n",
    "#         sub_2 = np.zeros((M,M))\n",
    "#         sub_3 = np.zeros((M,M))\n",
    "#         sub_4 = np.zeros((M,M))\n",
    "\n",
    "#         sub_5 = np.zeros((N,M))\n",
    "#         sub_6 = np.zeros((M,M))\n",
    "#         sub_7 = np.zeros((N,N))\n",
    "#         sub_8 = np.zeros((M,N))\n",
    "\n",
    "#         for i in range(1,self.T,1):\n",
    "#             sub_1 += np.matmul(self.V_hat[i],self.J[i-1].T) + np.outer(self.u_hat[i],self.u_hat[i-1].T) # z[n]z[n-1]\n",
    "            \n",
    "#             sub_2 += self.V_hat[i-1] + np.outer(self.u_hat[i-1], self.u_hat[i-1].T)\n",
    "\n",
    "\n",
    "#             sub_3 += self.V_hat[i] + np.outer(self.u_hat[i], self.u_hat[i].T) # z[n]z[n]\n",
    "#             sub_4 += (np.matmul(self.V_hat[i],self.J[i-1].T) + np.outer(self.u_hat[i],self.u_hat[i-1].T)).T #z[n-1]z[n]\n",
    "\n",
    "#         for i in range(self.T):\n",
    "#             sub_5 += np.outer(self.x[i], self.u_hat[i].T) # x[n] * E[z[n]].T\n",
    "#             sub_6 += self.V_hat[i] + np.outer(self.u_hat[i], self.u_hat[i].T) # z[n]z[n]\n",
    "#             sub_7 += np.outer(self.x[i], self.x[i].T) # x[n]x[n]\n",
    "#             sub_8 += np.outer(self.u_hat[i], self.x[i].T) #E[z[n]] * x[n].T \n",
    "\n",
    "#         self.A = np.matmul(sub_1, np.linalg.inv(sub_2))\n",
    "#         # print(sub_1,sub_2)\n",
    "#         # print(sub_4,sub_3)\n",
    "#         self.Gamma = 1/(self.T-1) * (sub_3 - np.matmul(self.A,sub_4) - np.matmul(sub_1,self.A.T) + np.matmul(np.matmul(self.A,sub_2),self.A.T))\n",
    "#         # self.Gamma = 1/(self.N-1) * (sub_3 - np.matmul(self.A, sub_4) )\n",
    "        \n",
    "#         self.C = np.matmul(sub_5, np.linalg.inv(sub_6))\n",
    "#         self.Sigma = 1/self.T * (sub_7 - np.matmul(self.C,sub_8) - np.matmul(sub_5,self.C.T) + np.matmul(np.matmul(self.C,sub_6),self.C.T))\n",
    "#         # self.Sigma = 1/self.N * (sub_7 - np.matmul(self.C, sub_8) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_examples(A = None, C=None, Gamma=None,Sigma=None,u0=None,V0=None,M=None,N=None,T=None,z0=None):\n",
    " \n",
    "    z = np.zeros((T,M))\n",
    "    x = np.zeros((T,N))\n",
    "    if z0 is not None:\n",
    "        z[0]=z0\n",
    "    else:\n",
    "        z[0] = np.random.multivariate_normal(u0,V0)\n",
    "    x[0] = np.random.multivariate_normal(np.matmul(C,z[0]),Sigma)\n",
    "    for t in range(1,T,1):\n",
    "        z[t] = np.random.multivariate_normal(np.matmul(A,z[t-1]),Gamma)\n",
    "        x[t] = np.random.multivariate_normal(np.matmul(C,z[t]),Sigma)\n",
    "    return z,x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_examples(N):\n",
    "\n",
    "    np.random.seed(1000)\n",
    "\n",
    "    # rotate pi / 6 radian in any axis\n",
    "    A = np.matmul(\n",
    "        np.matmul(\n",
    "            np.array([\n",
    "                [1.0,0.0,0.0],\n",
    "                [0.0,math.cos(math.pi/6),math.sin(math.pi/6)],\n",
    "                [0.0,-1.0*math.sin(math.pi/6),math.cos(math.pi/6)]\n",
    "            ]),\n",
    "            np.array([\n",
    "                [math.cos(math.pi/6),0.0,-1.0*math.sin(math.pi/6)],\n",
    "                [0.0,1.0,0.0],\n",
    "                [math.sin(math.pi/6),0.0,math.cos(math.pi/6)]\n",
    "            ])),\n",
    "        np.array([\n",
    "            [math.cos(math.pi/6),math.sin(math.pi/6),0.0],\n",
    "            [-1.0*math.sin(math.pi/6),math.cos(math.pi/6),0.0],\n",
    "            [0.0,0.0,1.0]\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    Gamma = np.array([\n",
    "        [1.5, 0.1, 0.0],\n",
    "        [0.1, 2.0, 0.3],\n",
    "        [0.0, 0.3, 1.0]\n",
    "    ])\n",
    "\n",
    "    Z = np.array([[23.0, 24.0, 25.0]])\n",
    "    for n in range(N):\n",
    "        z_prev = Z[len(Z) - 1]\n",
    "        mean = np.matmul(A, z_prev)\n",
    "        z_post = np.random.multivariate_normal(\n",
    "            mean=mean,\n",
    "            cov=Gamma,\n",
    "            size=1)\n",
    "        Z = np.vstack((Z, z_post))\n",
    "\n",
    "    C = np.array([\n",
    "        [1.0, 1.0, 0.0],\n",
    "        [0.0, 1.0, 1.0],\n",
    "    ])\n",
    "\n",
    "    Sigma = np.array([\n",
    "        [1.0,0.2],\n",
    "        [0.2,2.0],\n",
    "    ])\n",
    "\n",
    "    X = np.empty((0,2))\n",
    "    for z_n in Z:\n",
    "        mean = np.matmul(C, z_n)\n",
    "        x_n = np.random.multivariate_normal(\n",
    "            mean=mean,\n",
    "            cov=Sigma,\n",
    "            size=1)\n",
    "        X = np.vstack((X, x_n))\n",
    "    return Z, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_states = 3 # M\n",
    "# n_obs = 2 # N\n",
    "# n_time = 2000 # T\n",
    "# p_old = -10000\n",
    "# tol = 0.0001\n",
    "# max_iter = 100\n",
    "\n",
    "# # z: T x M\n",
    "# # x : T x N\n",
    "# # A = np.array([[0.9, 0.1],[0.5,0.5]])\n",
    "# # C = np.array([[1, 0],[0.2, 0.8]])\n",
    "# # Gamma = np.array([[0.1, 0.1], [0.1, 0.1]])\n",
    "# # Sigma = np.array([[0.5,0.5],[0.5,0.5]])\n",
    "\n",
    "# A = np.array([[0.75, 0.433, -0.5],[-0.217, 0.875, 0.433],[0.625, -0.217, 0.75]])\n",
    "# Gamma = np.array([[1.5, 0.1, 0.0], [0.1, 2.0, 0.3], [0.0, 0.3, 1.0]])\n",
    "# C = np.array([[1.0,1.0,0.0],[0.0,1.0,1.0]])\n",
    "# Sigma = np.array([[1.0,0.2], [0.2,2.0]])\n",
    "\n",
    "# u0 = np.array([1,2])\n",
    "# V0 = np.array([[0.1,0.3],[0.3,0.1]])\n",
    "\n",
    "# # A_init = np.array([[0.5, 0.5],[0.5,0.5]])\n",
    "# # C_init = np.array([[0.5, 0.5],[0.5, 0.5]])\n",
    "# # Gamma_init = np.array([[0.5, 0.9], [0.9, 4.5]])\n",
    "# # Sigma_init = np.array([[0.5, 0.9], [0.9, 2.5]])\n",
    "# # u0_init = np.array([1,2])\n",
    "# # V0_init = np.array([[0.2,0.5],[0.5,0.4]])\n",
    "\n",
    "# A_init = np.array([[1.0, 1.1, 1.2],[1.3, 1.4, 1.5],[1.6, 1.7, 1.8]])\n",
    "# C_init = np.array([[1.0,1.0,1.0], [1.0, 1.0,1.0]])\n",
    "# Gamma_init = np.array([[1.0, 0.5, 0.5], [0.5,1.0, 0.5],[0.5, 0.5, 1.0]])\n",
    "# Sigma_init = np.array([[1.0,0.5], [0.5,1.0]])\n",
    "# u0_init = np.array([10.0,10.0,10.0])\n",
    "# V0_init = np.array([[1.0, 0.5, 0.5], [0.5,1.0, 0.5],[0.5, 0.5, 1.0]])\n",
    "\n",
    "\n",
    "# # z,x = generate_examples(A,C,Gamma,Sigma,u0,V0,n_states,n_obs,n_time)\n",
    "# z,x = generate_examples(n_time)\n",
    "# kf = KalmanFilter(A = A_init, C = C_init, Gamma = Gamma_init, Sigma = Sigma_init, u0=u0_init, V0=V0_init,x=x,T=n_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in range(1,kf.T,1):\n",
    "#         kf.forward(t)\n",
    "# kf.u_hat[-1] = kf.u[-1]\n",
    "# kf.V_hat[-1] = kf.V[-1]\n",
    "\n",
    "# for t in range(kf.T-2,-1,-1):\n",
    "#     kf.backward(t)\n",
    "# kf.learning(z.shape[1],x.shape[1])\n",
    "\n",
    "# p = np.sum(np.log(kf.c))\n",
    "# print(f'The likelihood is {p}')\n",
    "# if p>p_old and p - p_old < tol:\n",
    "# \tbreak\n",
    "# p_old = p\n",
    "\n",
    "# S_temp = np.matmul(np.matmul(kf.C, kf.V0), kf.C.T) + kf.Sigma\n",
    "# Q_temp = np.matmul(kf.C, kf.u0)\n",
    "# I = np.eye(kf.M)\n",
    "# kf.V[0] = np.matmul((I - np.matmul(np.matmul(np.matmul(kf.V0, kf.C.T), np.linalg.inv(S_temp)), kf.C)), kf.V0)\n",
    "# kf.P[0] = np.matmul(np.matmul(kf.A, kf.V[0]), kf.A.T) + kf.Gamma\n",
    "# kf.K[0] = np.matmul(np.matmul(kf.P[0], kf.C.T), np.linalg.inv(S_temp))\n",
    "\n",
    "# kf.u[0] = kf.u0 + np.matmul(kf.K[0], kf.x[0] - Q_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(kf.u0,kf.V0,kf.A,kf.Gamma,kf.C,kf.Sigma)\n",
    "\n",
    "# print(kf.u_hat[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "\t\n",
    "# \tn_states = 3 # M\n",
    "# \tn_obs = 2 # N\n",
    "# \tn_time = 2000 # T\n",
    "# \tp_old = -10000\n",
    "# \ttol = 0.0001\n",
    "# \tmax_iter = 500\n",
    "\n",
    "# \t# z: T x M\n",
    "# \t# x : T x N\n",
    "# \t# A = np.array([[0.9, 0.1],[0.5,0.5]])\n",
    "# \t# C = np.array([[1, 0],[0.2, 0.8]])\n",
    "# \t# Gamma = np.array([[0.1, 0.1], [0.1, 0.1]])\n",
    "# \t# Sigma = np.array([[0.5,0.5],[0.5,0.5]])\n",
    "\n",
    "# \tA = np.array([[0.75, 0.433, -0.5],[-0.217, 0.875, 0.433],[0.625, -0.217, 0.75]])\n",
    "# \tGamma = np.array([[1.5, 0.1, 0.0], [0.1, 2.0, 0.3], [0.0, 0.3, 1.0]])\n",
    "# \tC = np.array([[1.0,1.0,0.0],[0.0,1.0,1.0]])\n",
    "# \tSigma = np.array([[1.0,0.2], [0.2,2.0]])\n",
    "\n",
    "# \tu0 = np.array([1,2])\n",
    "# \tV0 = np.array([[0.1,0.3],[0.3,0.1]])\n",
    "# \tz0 = np.array([[23.0, 24.0, 25.0]])\n",
    "# \t# A_init = np.array([[0.5, 0.5],[0.5,0.5]])\n",
    "# \t# C_init = np.array([[0.5, 0.5],[0.5, 0.5]])\n",
    "# \t# Gamma_init = np.array([[0.5, 0.9], [0.9, 4.5]])\n",
    "# \t# Sigma_init = np.array([[0.5, 0.9], [0.9, 2.5]])\n",
    "# \t# u0_init = np.array([1,2])\n",
    "# \t# V0_init = np.array([[0.2,0.5],[0.5,0.4]])\n",
    "\n",
    "# \tA_init = np.array([[1.0, 1.1, 1.2],[1.3, 1.4, 1.5],[1.6, 1.7, 1.8]])\n",
    "# \tC_init = np.array([[1.0,1.0,1.0], [1.0, 1.0,1.0]])\n",
    "# \tGamma_init = np.array([[1.0, 0.5, 0.5], [0.5,1.0, 0.5],[0.5, 0.5, 1.0]])\n",
    "# \tSigma_init = np.array([[1.0,0.5], [0.5,1.0]])\n",
    "# \tu0_init = np.array([10.0,10.0,10.0])\n",
    "# \tV0_init = np.array([[1.0, 0.5, 0.5], [0.5,1.0, 0.5],[0.5, 0.5, 1.0]])\n",
    "\n",
    "\n",
    "# \t# z,x = generate_examples(A = A, C = C, Gamma = Gamma, Sigma = Sigma, z0=z0,M=n_states,N=n_obs,T=n_time)\n",
    "# \tz,x = generate_examples(n_time)\n",
    "\n",
    "# \tkf = KalmanFilter(A = A_init, C = C_init, Gamma = Gamma_init, Sigma = Sigma_init, u0=u0_init, V0=V0_init,x=x, T=n_time)\n",
    "# \tfor ite in range(max_iter):\n",
    "# \t\tfor t in range(1,kf.T,1):\n",
    "# \t\t\tkf.forward(t)\n",
    "# \t\tkf.u_hat[-1] = kf.u[-1]\n",
    "# \t\tkf.V_hat[-1] = kf.V[-1]\n",
    "\n",
    "# \t\tfor t in range(kf.T-2,-1,-1):\n",
    "# \t\t\tkf.backward(t)\n",
    "# \t\tkf.learning(z.shape[1],x.shape[1])\n",
    "# \t\tp = np.sum(np.log(kf.c))\n",
    "# \t\tprint(f'The current iteration is: {ite}. The likelihood is {p}',end='\\r')\n",
    "# \t\tif p>p_old and p - p_old < tol:\n",
    "# \t\t\tbreak\n",
    "# \t\tp_old = p\n",
    "# \t\tS_temp = np.matmul(np.matmul(kf.C, kf.V0), kf.C.T) + kf.Sigma\n",
    "# \t\tQ_temp = np.matmul(kf.C, kf.u0)\n",
    "# \t\tI = np.eye(kf.M)\n",
    "# \t\tkf.V[0] = np.matmul((I - np.matmul(np.matmul(np.matmul(kf.V0, kf.C.T), np.linalg.inv(S_temp)), kf.C)), kf.V0)\n",
    "# \t\tkf.P[0] = np.matmul(np.matmul(kf.A, kf.V[0]), kf.A.T) + kf.Gamma\n",
    "# \t\tkf.K[0] = np.matmul(np.matmul(kf.P[0], kf.C.T), np.linalg.inv(np.matmul(np.matmul(kf.C, kf.P[0]), kf.C.T) + kf.Sigma))\n",
    "        \n",
    "# \t\tkf.u[0] = kf.u0 + np.matmul(kf.K[0], kf.x[0] - Q_temp)\n",
    "\t\t\n",
    "# \tprint('u0\\n',kf.u0,'\\nV0\\n',kf.V0,'\\nA\\n',kf.A,'\\nGamma\\n',kf.Gamma,'\\nC\\n',kf.C,'\\nSigma\\n',kf.Sigma)\n",
    "# \treturn kf,z,x\n",
    "\n",
    "# kf,z,x = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def is_symmetric_positive_semidefinite(matrix):\n",
    "#     if not np.allclose(matrix, matrix.T):\n",
    "#         return False  # Not symmetric\n",
    "#     eigenvalues = np.linalg.eigvals(matrix)\n",
    "#     return np.all(eigenvalues >= 0)\n",
    "\n",
    "# B = np.array([[35.62538664, 35.93218881],\n",
    "#  [35.93218881, 36.40284164]])\n",
    "# print(is_symmetric_positive_semidefinite(B)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7n/2hstn0kx2mvgvjzthjfyy7280000gn/T/ipykernel_7383/693181478.py:57: RuntimeWarning: divide by zero encountered in log\n",
      "  p = np.sum(np.log(kf.c))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current iteration is: 0. The likelihood is -inf\n",
      "The current iteration is: 1. The likelihood is -15565.165275830257\n",
      "The current iteration is: 2. The likelihood is -15253.890259621654\n",
      "The current iteration is: 3. The likelihood is -14933.83431583656\n",
      "The current iteration is: 4. The likelihood is -14695.062150900849\n",
      "The current iteration is: 5. The likelihood is -14550.916901558125\n",
      "The current iteration is: 6. The likelihood is -14471.953873998671\n",
      "The current iteration is: 7. The likelihood is -14428.634287359699\n",
      "The current iteration is: 8. The likelihood is -14402.371679544114\n",
      "The current iteration is: 9. The likelihood is -14383.899236198487\n",
      "The current iteration is: 10. The likelihood is -14369.17590297837\n",
      "The current iteration is: 11. The likelihood is -14356.555848987871\n",
      "The current iteration is: 12. The likelihood is -14345.37622919318\n",
      "The current iteration is: 13. The likelihood is -14335.350524397658\n",
      "The current iteration is: 14. The likelihood is -14326.327847306722\n",
      "The current iteration is: 15. The likelihood is -14318.203177611886\n",
      "The current iteration is: 16. The likelihood is -14310.886804359194\n",
      "The current iteration is: 17. The likelihood is -14304.295762207734\n",
      "The current iteration is: 18. The likelihood is -14298.352571436746\n",
      "The current iteration is: 19. The likelihood is -14292.985787085006\n",
      "The current iteration is: 20. The likelihood is -14288.130555302356\n",
      "The current iteration is: 21. The likelihood is -14283.728765970189\n",
      "The current iteration is: 22. The likelihood is -14279.728839943284\n",
      "The current iteration is: 23. The likelihood is -14276.085284529505\n",
      "The current iteration is: 24. The likelihood is -14272.758134790096\n",
      "The current iteration is: 25. The likelihood is -14269.712360628353\n",
      "The current iteration is: 26. The likelihood is -14266.917287437731\n",
      "The current iteration is: 27. The likelihood is -14264.346055879845\n",
      "The current iteration is: 28. The likelihood is -14261.975132443884\n",
      "The current iteration is: 29. The likelihood is -14259.783874189809\n",
      "The current iteration is: 30. The likelihood is -14257.754146432108\n",
      "The current iteration is: 31. The likelihood is -14255.869989701352\n",
      "The current iteration is: 32. The likelihood is -14254.117331227406\n",
      "The current iteration is: 33. The likelihood is -14252.483735876052\n",
      "The current iteration is: 34. The likelihood is -14250.958191593645\n",
      "The current iteration is: 35. The likelihood is -14249.530924769313\n",
      "The current iteration is: 36. The likelihood is -14248.193241369238\n",
      "The current iteration is: 37. The likelihood is -14246.937390162673\n",
      "The current iteration is: 38. The likelihood is -14245.756444750336\n",
      "The current iteration is: 39. The likelihood is -14244.644201243831\n",
      "The current iteration is: 40. The likelihood is -14243.595087729704\n",
      "The current iteration is: 41. The likelihood is -14242.604077846929\n",
      "The current iteration is: 42. The likelihood is -14241.666585526007\n",
      "The current iteration is: 43. The likelihood is -14240.778259619432\n",
      "The current iteration is: 44. The likelihood is -14239.934376833458\n",
      "The current iteration is: 45. The likelihood is -14239.127700181503\n",
      "The current iteration is: 46. The likelihood is -14238.340532855495\n",
      "The current iteration is: 47. The likelihood is -14237.514849054762\n",
      "The current iteration is: 48. The likelihood is -14236.439669645006\n",
      "The current iteration is: 49. The likelihood is -14234.327083019009\n",
      "The current iteration is: 50. The likelihood is -14228.23446832813\n",
      "The current iteration is: 51. The likelihood is -14207.463854550584\n",
      "The current iteration is: 52. The likelihood is -14137.017429031632\n",
      "The current iteration is: 53. The likelihood is -13936.15419690541\n",
      "The current iteration is: 54. The likelihood is -13540.84381366022\n",
      "The current iteration is: 55. The likelihood is -13024.842735162467\n",
      "The current iteration is: 56. The likelihood is -12501.116103283439\n",
      "The current iteration is: 57. The likelihood is -12017.698202946243\n",
      "The current iteration is: 58. The likelihood is -11580.716212809393\n",
      "The current iteration is: 59. The likelihood is -11185.274860958101\n",
      "The current iteration is: 60. The likelihood is -10827.884442902367\n",
      "The current iteration is: 61. The likelihood is -10508.992978464896\n",
      "The current iteration is: 62. The likelihood is -10231.91537201716\n",
      "The current iteration is: 63. The likelihood is -10000.626831580073\n",
      "The current iteration is: 64. The likelihood is -9817.295510326217\n",
      "The current iteration is: 65. The likelihood is -9680.367346555839\n",
      "The current iteration is: 66. The likelihood is -9584.125259850349\n",
      "The current iteration is: 67. The likelihood is -9520.012471132946\n",
      "The current iteration is: 68. The likelihood is -9478.890047806693\n",
      "The current iteration is: 69. The likelihood is -9452.923263349214\n",
      "The current iteration is: 70. The likelihood is -9436.387772137681\n",
      "The current iteration is: 71. The likelihood is -9425.554181098832\n",
      "The current iteration is: 72. The likelihood is -9418.168544859333\n",
      "The current iteration is: 73. The likelihood is -9412.920890022027\n",
      "The current iteration is: 74. The likelihood is -9409.054982194739\n",
      "The current iteration is: 75. The likelihood is -9406.125159584062\n",
      "The current iteration is: 76. The likelihood is -9403.857983818842\n",
      "The current iteration is: 77. The likelihood is -9402.07708296512\n",
      "The current iteration is: 78. The likelihood is -9400.662872428224\n",
      "The current iteration is: 79. The likelihood is -9399.530692902808\n",
      "The current iteration is: 80. The likelihood is -9398.618539463074\n",
      "The current iteration is: 81. The likelihood is -9397.879836602799\n",
      "The current iteration is: 82. The likelihood is -9397.27894833031\n",
      "The current iteration is: 83. The likelihood is -9396.788238557445\n",
      "The current iteration is: 84. The likelihood is -9396.386057684367\n",
      "The current iteration is: 85. The likelihood is -9396.055313023324\n",
      "The current iteration is: 86. The likelihood is -9395.782425375948\n",
      "The current iteration is: 87. The likelihood is -9395.556551460922\n",
      "The current iteration is: 88. The likelihood is -9395.36899525892\n",
      "The current iteration is: 89. The likelihood is -9395.212756818146\n",
      "The current iteration is: 90. The likelihood is -9395.082183079092\n",
      "The current iteration is: 91. The likelihood is -9394.97269542013\n",
      "The current iteration is: 92. The likelihood is -9394.8805756841\n",
      "The current iteration is: 93. The likelihood is -9394.802797158376\n",
      "The current iteration is: 94. The likelihood is -9394.736890412954\n",
      "The current iteration is: 95. The likelihood is -9394.680836371412\n",
      "The current iteration is: 96. The likelihood is -9394.632980762432\n",
      "The current iteration is: 97. The likelihood is -9394.591965470432\n",
      "The current iteration is: 98. The likelihood is -9394.556673280873\n",
      "The current iteration is: 99. The likelihood is -9394.526183306532\n",
      "The current iteration is: 100. The likelihood is -9394.499734941297\n",
      "The current iteration is: 101. The likelihood is -9394.476698654606\n",
      "The current iteration is: 102. The likelihood is -9394.456552286609\n",
      "The current iteration is: 103. The likelihood is -9394.438861771454\n",
      "The current iteration is: 104. The likelihood is -9394.423265443813\n",
      "The current iteration is: 105. The likelihood is -9394.409461232124\n",
      "The current iteration is: 106. The likelihood is -9394.39719620749\n",
      "The current iteration is: 107. The likelihood is -9394.38625802805\n",
      "The current iteration is: 108. The likelihood is -9394.376467937116\n",
      "The current iteration is: 109. The likelihood is -9394.367675019072\n",
      "The current iteration is: 110. The likelihood is -9394.359751482021\n",
      "The current iteration is: 111. The likelihood is -9394.35258878001\n",
      "The current iteration is: 112. The likelihood is -9394.346094417228\n",
      "The current iteration is: 113. The likelihood is -9394.340189315924\n",
      "The current iteration is: 114. The likelihood is -9394.33480563937\n",
      "The current iteration is: 115. The likelihood is -9394.32988499201\n",
      "The current iteration is: 116. The likelihood is -9394.325376928942\n",
      "The current iteration is: 117. The likelihood is -9394.321237718073\n",
      "The current iteration is: 118. The likelihood is -9394.317429310682\n",
      "The current iteration is: 119. The likelihood is -9394.313918484251\n",
      "The current iteration is: 120. The likelihood is -9394.31067612699\n",
      "The current iteration is: 121. The likelihood is -9394.307676638862\n",
      "The current iteration is: 122. The likelihood is -9394.304897429913\n",
      "The current iteration is: 123. The likelihood is -9394.302318498165\n",
      "The current iteration is: 124. The likelihood is -9394.299922075086\n",
      "The current iteration is: 125. The likelihood is -9394.297692325057\n",
      "The current iteration is: 126. The likelihood is -9394.295615091645\n",
      "The current iteration is: 127. The likelihood is -9394.293677681777\n",
      "The current iteration is: 128. The likelihood is -9394.29186868239\n",
      "The current iteration is: 129. The likelihood is -9394.290177803105\n",
      "The current iteration is: 130. The likelihood is -9394.288595742531\n",
      "The current iteration is: 131. The likelihood is -9394.287114072611\n",
      "The current iteration is: 132. The likelihood is -9394.285725139038\n",
      "The current iteration is: 133. The likelihood is -9394.284421975415\n",
      "The current iteration is: 134. The likelihood is -9394.283198228579\n",
      "The current iteration is: 135. The likelihood is -9394.282048093792\n",
      "The current iteration is: 136. The likelihood is -9394.280966257895\n",
      "The current iteration is: 137. The likelihood is -9394.279947849831\n",
      "The current iteration is: 138. The likelihood is -9394.278988396782\n",
      "The current iteration is: 139. The likelihood is -9394.27808378597\n",
      "The current iteration is: 140. The likelihood is -9394.277230230622\n",
      "The current iteration is: 141. The likelihood is -9394.276424239655\n",
      "The current iteration is: 142. The likelihood is -9394.275662590959\n",
      "The current iteration is: 143. The likelihood is -9394.274942307504\n",
      "The current iteration is: 144. The likelihood is -9394.274260635975\n",
      "The current iteration is: 145. The likelihood is -9394.273615027545\n",
      "The current iteration is: 146. The likelihood is -9394.273003120526\n",
      "The current iteration is: 147. The likelihood is -9394.272422725016\n",
      "The current iteration is: 148. The likelihood is -9394.27187180873\n",
      "The current iteration is: 149. The likelihood is -9394.271348484404\n",
      "The current iteration is: 150. The likelihood is -9394.270850998224\n",
      "The current iteration is: 151. The likelihood is -9394.27037771932\n",
      "The current iteration is: 152. The likelihood is -9394.269927130303\n",
      "The current iteration is: 153. The likelihood is -9394.269497818519\n",
      "The current iteration is: 154. The likelihood is -9394.269088468209\n",
      "The current iteration is: 155. The likelihood is -9394.268697853067\n",
      "The current iteration is: 156. The likelihood is -9394.268324829809\n",
      "The current iteration is: 157. The likelihood is -9394.26796833193\n",
      "The current iteration is: 158. The likelihood is -9394.267627364148\n",
      "The current iteration is: 159. The likelihood is -9394.267300997231\n",
      "The current iteration is: 160. The likelihood is -9394.266988363303\n",
      "The current iteration is: 161. The likelihood is -9394.266688651454\n",
      "The current iteration is: 162. The likelihood is -9394.26640110363\n",
      "The current iteration is: 163. The likelihood is -9394.266125011098\n",
      "The current iteration is: 164. The likelihood is -9394.265859710824\n",
      "The current iteration is: 165. The likelihood is -9394.265604582437\n",
      "The current iteration is: 166. The likelihood is -9394.26535904523\n",
      "The current iteration is: 167. The likelihood is -9394.265122555431\n",
      "The current iteration is: 168. The likelihood is -9394.264894603708\n",
      "The current iteration is: 169. The likelihood is -9394.264674712806\n",
      "The current iteration is: 170. The likelihood is -9394.264462435436\n",
      "The current iteration is: 171. The likelihood is -9394.264257352239\n",
      "The current iteration is: 172. The likelihood is -9394.264059069883\n",
      "The current iteration is: 173. The likelihood is -9394.263867219375\n",
      "The current iteration is: 174. The likelihood is -9394.263681454418\n",
      "The current iteration is: 175. The likelihood is -9394.263501449943\n",
      "The current iteration is: 176. The likelihood is -9394.263326900713\n",
      "The current iteration is: 177. The likelihood is -9394.263157519958\n",
      "The current iteration is: 178. The likelihood is -9394.262993038335\n",
      "The current iteration is: 179. The likelihood is -9394.262833202594\n",
      "The current iteration is: 180. The likelihood is -9394.26267777471\n",
      "The current iteration is: 181. The likelihood is -9394.26252653077\n",
      "The current iteration is: 182. The likelihood is -9394.26237926016\n",
      "The current iteration is: 183. The likelihood is -9394.262235764703\n",
      "The current iteration is: 184. The likelihood is -9394.262095857826\n",
      "The current iteration is: 185. The likelihood is -9394.261959363841\n",
      "The current iteration is: 186. The likelihood is -9394.26182611727\n",
      "The current iteration is: 187. The likelihood is -9394.261695962181\n",
      "The current iteration is: 188. The likelihood is -9394.261568751626\n",
      "The current iteration is: 189. The likelihood is -9394.261444347034\n",
      "The current iteration is: 190. The likelihood is -9394.261322617727\n",
      "The current iteration is: 191. The likelihood is -9394.261203440432\n",
      "The current iteration is: 192. The likelihood is -9394.261086698767\n",
      "The current iteration is: 193. The likelihood is -9394.260972282893\n",
      "The current iteration is: 194. The likelihood is -9394.26086008903\n",
      "The current iteration is: 195. The likelihood is -9394.26075001918\n",
      "The current iteration is: 196. The likelihood is -9394.260641980705\n",
      "The current iteration is: 197. The likelihood is -9394.260535886027\n",
      "The current iteration is: 198. The likelihood is -9394.260431652294\n",
      "The current iteration is: 199. The likelihood is -9394.260329201174\n",
      "The current iteration is: 200. The likelihood is -9394.260228458475\n",
      "The current iteration is: 201. The likelihood is -9394.260129353996\n"
     ]
    }
   ],
   "source": [
    "\t\n",
    "n_states = 3 # M\n",
    "n_obs = 2 # N\n",
    "n_time = 2000 # T\n",
    "p_old = -10000\n",
    "tol = 0.0001\n",
    "max_iter = 500\n",
    "\n",
    "# z: T x M\n",
    "# x : T x N\n",
    "# A = np.array([[0.9, 0.1],[0.5,0.5]])\n",
    "# C = np.array([[1, 0],[0.2, 0.8]])\n",
    "# Gamma = np.array([[0.1, 0.1], [0.1, 0.1]])\n",
    "# Sigma = np.array([[0.5,0.5],[0.5,0.5]])\n",
    "\n",
    "A = np.array([[0.75, 0.433, -0.5],[-0.217, 0.875, 0.433],[0.625, -0.217, 0.75]])\n",
    "Gamma = np.array([[1.5, 0.1, 0.0], [0.1, 2.0, 0.3], [0.0, 0.3, 1.0]])\n",
    "C = np.array([[1.0,1.0,0.0],[0.0,1.0,1.0]])\n",
    "Sigma = np.array([[1.0,0.2], [0.2,2.0]])\n",
    "\n",
    "u0 = np.array([1,2])\n",
    "V0 = np.array([[0.1,0.3],[0.3,0.1]])\n",
    "z0 = np.array([[23.0, 24.0, 25.0]])\n",
    "# A_init = np.array([[0.5, 0.5],[0.5,0.5]])\n",
    "# C_init = np.array([[0.5, 0.5],[0.5, 0.5]])\n",
    "# Gamma_init = np.array([[0.5, 0.9], [0.9, 4.5]])\n",
    "# Sigma_init = np.array([[0.5, 0.9], [0.9, 2.5]])\n",
    "# u0_init = np.array([1,2])\n",
    "# V0_init = np.array([[0.2,0.5],[0.5,0.4]])\n",
    "\n",
    "A_init = np.array([[1.0, 1.1, 1.2],[1.3, 1.4, 1.5],[1.6, 1.7, 1.8]])\n",
    "A_init = np.tile(A_init,(n_time,1)).reshape(n_time,n_states,n_states)\n",
    "C_init = np.array([[1.0,1.0,1.0], [1.0, 1.0,1.0]])\n",
    "C_init = np.tile(C_init,(n_time,1)).reshape(n_time,n_obs,n_states)\n",
    "Gamma_init = np.array([[1.0, 0.5, 0.5], [0.5,1.0, 0.5],[0.5, 0.5, 1.0]])\n",
    "Gamma_init = np.tile(Gamma_init,(n_time,1)).reshape(n_time,n_states,n_states)\n",
    "Sigma_init = np.array([[1.0,0.5], [0.5,1.0]])\n",
    "Sigma_init = np.tile(Sigma_init,(n_time,1)).reshape(n_time,n_obs,n_obs)\n",
    "u0_init = np.array([10.0,10.0,10.0])\n",
    "V0_init = np.array([[1.0, 0.5, 0.5], [0.5,1.0, 0.5],[0.5, 0.5, 1.0]])\n",
    "\n",
    "\n",
    "# z,x = generate_examples(A = A, C = C, Gamma = Gamma, Sigma = Sigma, z0=z0,M=n_states,N=n_obs,T=n_time)\n",
    "z,x = generate_examples(n_time)\n",
    "\n",
    "# kf = KalmanFilter(A = A_init, C = C_init, Gamma = Gamma_init, Sigma = Sigma_init, u0=u0_init, V0=V0_init,x=x, T=n_time)\n",
    "kf = timeVaryingLDS(T=n_time, transition_con = A_init, emission = C_init, Q = Gamma_init, R = Sigma_init, u0 = u0_init, V0 = V0_init, y=x)\n",
    "for ite in range(max_iter):\n",
    "\tkf.kalman_filtering()\n",
    "\tkf.kalman_smoothing()        \n",
    "\tkf.kalman_learning()\n",
    "\tkf.A = np.tile(kf.A,(n_time,1)).reshape(n_time,n_states,n_states)\n",
    "\tkf.C = np.tile(kf.C,(n_time,1)).reshape(n_time,n_obs,n_states)\n",
    "\tkf.Q = np.tile(kf.Q,(n_time,1)).reshape(n_time,n_states,n_states)\n",
    "\tkf.R = np.tile(kf.R,(n_time,1)).reshape(n_time,n_obs,n_obs)\n",
    "\n",
    "\n",
    "\tp = np.sum(np.log(kf.c))\n",
    "\tprint(f'The current iteration is: {ite}. The likelihood is {p}')\n",
    "\tif p>p_old and p - p_old < tol:\n",
    "\t\tbreak\n",
    "\tp_old = p\n",
    "\n",
    "\t\t\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.57586593,  6.32547029, 11.23287769])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf.u0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.86585762e-05, 1.97320968e-05, 3.93619273e-05],\n",
       "       [1.97320968e-05, 8.03711620e-05, 8.96698792e-05],\n",
       "       [3.93619273e-05, 8.96698792e-05, 1.61063488e-04]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf.V0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.78572376, -0.54701062,  0.37224728],\n",
       "        [ 0.89507198,  0.8719739 , -0.11777778],\n",
       "        [ 0.10619124,  0.4347636 ,  0.71636109]],\n",
       "\n",
       "       [[ 0.78572376, -0.54701062,  0.37224728],\n",
       "        [ 0.89507198,  0.8719739 , -0.11777778],\n",
       "        [ 0.10619124,  0.4347636 ,  0.71636109]],\n",
       "\n",
       "       [[ 0.78572376, -0.54701062,  0.37224728],\n",
       "        [ 0.89507198,  0.8719739 , -0.11777778],\n",
       "        [ 0.10619124,  0.4347636 ,  0.71636109]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.78572376, -0.54701062,  0.37224728],\n",
       "        [ 0.89507198,  0.8719739 , -0.11777778],\n",
       "        [ 0.10619124,  0.4347636 ,  0.71636109]],\n",
       "\n",
       "       [[ 0.78572376, -0.54701062,  0.37224728],\n",
       "        [ 0.89507198,  0.8719739 , -0.11777778],\n",
       "        [ 0.10619124,  0.4347636 ,  0.71636109]],\n",
       "\n",
       "       [[ 0.78572376, -0.54701062,  0.37224728],\n",
       "        [ 0.89507198,  0.8719739 , -0.11777778],\n",
       "        [ 0.10619124,  0.4347636 ,  0.71636109]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-15.91424657,  -3.14426686,   9.66563821],\n",
       "        [ 19.56404236,   7.57026609,  -4.39918558]],\n",
       "\n",
       "       [[-15.91424657,  -3.14426686,   9.66563821],\n",
       "        [ 19.56404236,   7.57026609,  -4.39918558]],\n",
       "\n",
       "       [[-15.91424657,  -3.14426686,   9.66563821],\n",
       "        [ 19.56404236,   7.57026609,  -4.39918558]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-15.91424657,  -3.14426686,   9.66563821],\n",
       "        [ 19.56404236,   7.57026609,  -4.39918558]],\n",
       "\n",
       "       [[-15.91424657,  -3.14426686,   9.66563821],\n",
       "        [ 19.56404236,   7.57026609,  -4.39918558]],\n",
       "\n",
       "       [[-15.91424657,  -3.14426686,   9.66563821],\n",
       "        [ 19.56404236,   7.57026609,  -4.39918558]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.90513295, 0.02240543],\n",
       "        [0.02240543, 1.89674818]],\n",
       "\n",
       "       [[0.90513295, 0.02240543],\n",
       "        [0.02240543, 1.89674818]],\n",
       "\n",
       "       [[0.90513295, 0.02240543],\n",
       "        [0.02240543, 1.89674818]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.90513295, 0.02240543],\n",
       "        [0.02240543, 1.89674818]],\n",
       "\n",
       "       [[0.90513295, 0.02240543],\n",
       "        [0.02240543, 1.89674818]],\n",
       "\n",
       "       [[0.90513295, 0.02240543],\n",
       "        [0.02240543, 1.89674818]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
