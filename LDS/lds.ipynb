{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanFilter(object):\n",
    "    def __init__(self, A = None, C = None, Gamma = None, Sigma = None, P = None, u0 = None, V0 = None,x=None):\n",
    "\n",
    "        if(A is None or C is None):\n",
    "            raise ValueError(\"Set proper system dynamics.\")\n",
    "\n",
    "        self.x = x # T x N\n",
    "        self.M = A.shape[0] # dimension of hidden states\n",
    "        self.T = self.x.shape[0] # number of observations\n",
    "        self.N = self.x.shape[1] # number of dimension of the observations\n",
    "\n",
    "        self.A = A # A is the transition probability matrix, M x M \n",
    "        self.C = C # C is the emission probability matrix, N x M\n",
    "        \n",
    "        self.Gamma = np.eye(self.M) if Gamma is None else Gamma # Gamma is the covariance matrix of noise term added to the hidden state transition, M x M\n",
    "        self.Sigma = np.eye(self.M) if Sigma is None else Sigma # Sigma is the covariance matrix of noise term added to the emission, N x N\n",
    "        \n",
    "        self.P = np.zeros((self.T, self.M, self.M))\n",
    "        self.P[0:-1,:,] = np.eye(self.M) if P is None else P # P is an intermediate variable during inference, N x M x M\n",
    "        self.u = np.zeros((self.T, self.M)) # T x M x 1\n",
    "        self.V = np.zeros((self.T, self.M, self.M)) # T x M x M\n",
    "        self.K = np.zeros((self.T, self.M, self.N)) # T x M x N\n",
    "        self.c = np.zeros((self.T)) # T x 1\n",
    "\n",
    "        # for backward passing\n",
    "        self.u_hat = np.zeros((self.T, self.M)) # T x M x 1\n",
    "        self.V_hat = np.zeros((self.T, self.M, self.M)) # T x M x M\n",
    "        self.J = np.zeros((self.T, self.M, self.M)) # T x M x M\n",
    "\n",
    "        self.u0 = u0 # u0 is the initial estimate of the mean of z1, M x 1\n",
    "        self.V0 = V0 # V0 is the initial estimate of the variance of z1, M x M\n",
    "        \n",
    "        S = np.dot(np.dot(self.C, self.V0), self.C.T) + self.Sigma\n",
    "        J = np.dot(self.C, self.u0)\n",
    "        I = np.eye(self.M)\n",
    "\n",
    "        self.K[0] = np.dot(np.dot(self.V0, self.C.T), np.linalg.inv(S))\n",
    "        self.u[0] = self.u0 + np.dot(self.K[0], self.x[0] - J)\n",
    "        self.V[0] = np.dot((I - np.dot(self.K[0], self.C)), self.V0)\n",
    "\n",
    "        self.c[0] = multivariate_normal.pdf(self.x[0], J, S)\n",
    "    \n",
    "    def forward(self,i):\n",
    "        # during inference, u[n], V[n], c[n] are calculated\n",
    "        self.P[i-1] = np.dot(np.dot(self.A, self.V[i-1]), self.A.T) + self.Gamma\n",
    "        I = np.eye(self.M)\n",
    "        S = np.dot(np.dot(self.C, self.P[i-1]), self.C.T) + self.Sigma\n",
    "        J = np.dot(np.dot(self.C, self.A), self.u[i-1])\n",
    "        \n",
    "        self.K[i] = np.dot(np.dot(self.P[i-1], self.C.T), np.linalg.inv(S))\n",
    "        self.u[i] = np.dot(self.A, self.u[i-1]) + np.dot(self.K[i], self.x[i] - J)\n",
    "        self.V[i] = np.dot((I - np.dot(self.K[i], self.C)), self.P[i-1])\n",
    "        self.c[i] = multivariate_normal.pdf(self.x[i], J, S)\n",
    "\n",
    "    def backward(self,i):\n",
    "        print(self.V[i],self.P[i])\n",
    "        self.J[i] = np.dot(np.dot(self.V[i], self.A.T), np.linalg.inv(self.P[i]))\n",
    "        self.u_hat[i] = self.u[i] + np.dot(self.J[i], self.u_hat[i+1] - np.dot(self.A, self.u[-1]))\n",
    "        self.V_hat[i] = self.V[i] + np.dot(np.dot(self.J[i], self.V_hat[i+1] - self.P[i]), self.J[i].T)\n",
    "    def learning(self):\n",
    "        self.u0 = self.u_hat[0]\n",
    "        self.V0 = self.V_hat[0] + np.outer(self.u_hat[0], self.u_hat[0].T) - np.outer(self.u_hat[0], self.u_hat[0].T)\n",
    "\n",
    "        # E[z[n]] : M x 1\n",
    "        # E[z[n]z[n-1].T] : M x M\n",
    "        # E[z[n]z[n].T] : M x M\n",
    "\n",
    "        sub_1 = []\n",
    "        sub_2 = []\n",
    "        sub_3 = []\n",
    "        sub_4 = []\n",
    "        sub_5 = []\n",
    "        sub_6 = []\n",
    "        sub_7 = []\n",
    "        sub_8 = []\n",
    "        for i in range(1,1,self.T):\n",
    "            sub_1 += np.dot(self.J[i-1], self.V_hat[i]) + np.outer(self.u_hat[i],self.u_hat[i-1].T) # z[n]z[n-1]\n",
    "            sub_2 += self.V_hat[i-1] + np.outer(self.u_hat[i-1], self.u_hat[i-1].T) # z[n-1]z[n-1]\n",
    "            sub_3 += self.V_hat[i] + np.outer(self.u_hat[i], self.u_hat[i].T) # z[n]z[n]\n",
    "            sub_4 += np.dot(self.J[i-1], self.V_hat[i]) + np.outer(self.u_hat[i-1],self.u_hat[i].T) #z[n-1]z[n]\n",
    "    \n",
    "        for i in range(self.T):\n",
    "            sub_5 += np.outer(self.x[i], self.u_hat[i].T) # x[n]*E[z[n]]\n",
    "            sub_6 += self.V_hat[i] + np.outer(self.u_hat[i], self.u_hat[i].T) # z[n]z[n]\n",
    "            sub_7 += np.outer(self.x[i], self.x[i].T) # x[n]x[n]\n",
    "            sub_8 += np.outer(self.u_hat[i], self.x[i].T) #E[z[n]]*x[n]\n",
    "\n",
    "        self.A = np.dot(sub_1, np.linalg.inv(sub_2))\n",
    "        self.Gamma = 1/(self.N-1) * (sub_3 - np.dot(self.A, sub_4) - np.dot(sub_1, self.A) + np.dot(np.dot(self.A, sub_2), self.A.T))\n",
    "        self.C = np.dot(sub_5, np.linalg.inv(sub_6))\n",
    "        self.Sigma = 1/self.N * (sub_7 - np.dot(self.C, sub_8) - np.dot(sub_5, self.C) + np.dot(np.dot(self.C, sub_6), self.C))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_examples(A, C, Gamma,Sigma,u0,V0,M,N,T):\n",
    "    z = np.zeros((T,M))\n",
    "    x = np.zeros((T,N))\n",
    "    z[0] = np.random.multivariate_normal(u0,V0)\n",
    "    x[0] = np.random.multivariate_normal(np.dot(C,z[0]),Sigma)\n",
    "    for t in range(1,1,T):\n",
    "        z[t] = np.random.multivariate_normal(np.dot(A,z[t-1]),Gamma)\n",
    "        x[t] = np.random.multivariate_normal(np.dot(C,z[t]),Sigma)\n",
    "    return z,x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70699615 1.98140991] [1.5 1.5] [[0.9 1.3]\n",
      " [1.3 4.9]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]] [[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0.05588235 0.31470588]\n",
      " [0.31470588 0.16176471]] [[1. 0.]\n",
      " [0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_561513/3978775153.py:4: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n",
      "  z[0] = np.random.multivariate_normal(u0,V0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (0,) (2,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 47\u001b[0m\n\u001b[1;32m     42\u001b[0m \t\tp_old \u001b[38;5;241m=\u001b[39m p\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[40], line 38\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(kf\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     37\u001b[0m \tkf\u001b[38;5;241m.\u001b[39mbackward(t)\n\u001b[0;32m---> 38\u001b[0m \u001b[43mkf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m p \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mlog(kf\u001b[38;5;241m.\u001b[39mc))\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m>\u001b[39mp_old \u001b[38;5;129;01mand\u001b[39;00m p \u001b[38;5;241m-\u001b[39m p_old \u001b[38;5;241m<\u001b[39m tol:\n",
      "Cell \u001b[0;32mIn[38], line 83\u001b[0m, in \u001b[0;36mKalmanFilter.learning\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m     sub_4 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mJ[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV_hat[i]) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mouter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mu_hat[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mu_hat[i]\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;66;03m#z[n-1]z[n]\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT):\n\u001b[0;32m---> 83\u001b[0m     sub_5 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mouter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mu_hat[i]\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;66;03m# x[n]*E[z[n]]\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     sub_6 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV_hat[i] \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mouter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mu_hat[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mu_hat[i]\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;66;03m# z[n]z[n]\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     sub_7 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mouter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx[i]\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;66;03m# x[n]x[n]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (0,) (2,2) "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\t\n",
    "\tn_states = 2 # M\n",
    "\tn_obs = 2 # N\n",
    "\tn_time = 100 # T\n",
    "\tp_old = -10000\n",
    "\ttol = 0.01\n",
    "\tmax_iter = 100\n",
    "\n",
    "\t# z: T x M\n",
    "\t# x : T x N\n",
    "\tA = np.array([[0.9, 0.1],[0.5,0.5]])\n",
    "\tC = np.array([[1, 0],[0.2, 0.8]])\n",
    "\t\n",
    "\tGamma = np.array([[0.1, 0.1], [0.1, 0.1]])\n",
    "\tSigma = np.array([[0.5,0.5],[0.5,0.5]])\n",
    "\tu0 = np.array([1,2])\n",
    "\tV0 = np.array([[0.1,0.3],[0.3,0.1]])\n",
    "\n",
    "\tA_init = np.array([[0.5, 0.5],[0.5,0.5]])\n",
    "\tC_init = np.array([[0.5, 0.5],[0.5, 0.5]])\n",
    "\t\n",
    "\tGamma_init = np.array([[0.5, 0.9], [0.9, 4.5]])\n",
    "\tSigma_init = np.array([[0.5, 0.9], [0.9, 4.5]])\n",
    "\tu0_init = np.array([1,2])\n",
    "\tV0_init = np.array([[0.2,0.5],[0.5,0.4]])\n",
    "\n",
    "\n",
    "\tz,x = generate_examples(A,C,Gamma,Sigma,u0,V0,n_states,n_obs,n_time)\n",
    "\n",
    "\tkf = KalmanFilter(A = A_init, C = C_init, Gamma = Gamma_init, Sigma = Sigma_init, u0=u0_init, V0=V0_init,x=x)\n",
    "\t\n",
    "\tfor ite in range(max_iter):\n",
    "\t\tfor t in range(1,1,kf.T):\n",
    "\t\t\tkf.forward(t)\n",
    "\t\tfor t in range(kf.T-2,-1,-1):\n",
    "\t\t\tkf.backward(t)\n",
    "\t\tkf.learning()\n",
    "\t\tp = np.sum(np.log(kf.c))\n",
    "\t\tif p>p_old and p - p_old < tol:\n",
    "\t\t\tbreak\n",
    "\t\tp_old = p\n",
    "\t\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
