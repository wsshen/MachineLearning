{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanFilter(object):\n",
    "    def __init__(self, A = None, C = None, Gamma = None, Sigma = None, P = None, u0 = None, V0 = None,x=None):\n",
    "\n",
    "        if(A is None or C is None):\n",
    "            raise ValueError(\"Set proper system dynamics.\")\n",
    "\n",
    "        self.x = x # T x N\n",
    "        self.M = A.shape[0] # dimension of hidden states\n",
    "        self.T = self.x.shape[0] # number of observations\n",
    "        self.N = self.x.shape[1] # number of dimension of the observations\n",
    "\n",
    "        self.A = A # A is the transition probability matrix, M x M \n",
    "        self.C = C # C is the emission probability matrix, N x M\n",
    "        \n",
    "        self.Gamma = np.eye(self.M) if Gamma is None else Gamma # Gamma is the covariance matrix of noise term added to the hidden state transition, M x M\n",
    "        self.Sigma = np.eye(self.M) if Sigma is None else Sigma # Sigma is the covariance matrix of noise term added to the emission, N x N\n",
    "        \n",
    "        self.P = np.zeros((self.T, self.M, self.M))\n",
    "        self.P[0:-1,:,] = np.eye(self.M) if P is None else P # P is an intermediate variable during inference, N x M x M\n",
    "        self.u = np.zeros((self.T, self.M)) # T x M x 1\n",
    "        self.V = np.zeros((self.T, self.M, self.M)) # T x M x M\n",
    "        self.K = np.zeros((self.T, self.M, self.N)) # T x M x N\n",
    "        self.c = np.zeros((self.T)) # T x 1\n",
    "\n",
    "        # for backward passing\n",
    "        self.u_hat = np.zeros((self.T, self.M)) # T x M x 1\n",
    "        self.V_hat = np.zeros((self.T, self.M, self.M)) # T x M x M\n",
    "        self.J = np.zeros((self.T, self.M, self.M)) # T x M x M\n",
    "\n",
    "        self.u0 = u0 # u0 is the initial estimate of the mean of z1, M x 1\n",
    "        self.V0 = V0 # V0 is the initial estimate of the variance of z1, M x M\n",
    "        \n",
    "        S = np.dot(np.dot(self.C, self.V0), self.C.T) + self.Sigma\n",
    "        J = np.dot(self.C, self.u0)\n",
    "        I = np.eye(self.M)\n",
    "\n",
    "        self.K[0] = np.dot(np.dot(self.V0, self.C.T), np.linalg.inv(S))\n",
    "        self.u[0] = self.u0 + np.dot(self.K[0], self.x[0] - J)\n",
    "        self.V[0] = np.dot((I - np.dot(self.K[0], self.C)), self.V0)\n",
    "\n",
    "        self.c[0] = multivariate_normal.pdf(self.x[0], J, S)\n",
    "    \n",
    "    def forward(self,i):\n",
    "        # during inference, u[n], V[n], c[n] are calculated\n",
    "        self.P[i-1] = np.dot(np.dot(self.A, self.V[i-1]), self.A.T) + self.Gamma\n",
    "        I = np.eye(self.M)\n",
    "        S = np.dot(np.dot(self.C, self.P[i-1]), self.C.T) + self.Sigma\n",
    "        J = np.dot(np.dot(self.C, self.A), self.u[i-1])\n",
    "        \n",
    "        self.K[i] = np.dot(np.dot(self.P[i-1], self.C.T), np.linalg.inv(S))\n",
    "        self.u[i] = np.dot(self.A, self.u[i-1]) + np.dot(self.K[i], self.x[i] - J)\n",
    "        self.V[i] = np.dot((I - np.dot(self.K[i], self.C)), self.P[i-1])\n",
    "        self.c[i] = multivariate_normal.pdf(self.x[i], J, S)\n",
    "\n",
    "    def backward(self,i):\n",
    "        self.J[i] = np.dot(np.dot(self.V[i], self.A.T), np.linalg.inv(self.P[i]))\n",
    "        self.u_hat[i] = self.u[i] + np.dot(self.J[i], self.u_hat[i+1] - np.dot(self.A, self.u[-1]))\n",
    "        self.V_hat[i] = self.V[i] + np.dot(np.dot(self.J[i], self.V_hat[i+1] - self.P[i]), self.J[i].T)\n",
    "    def learning(self,M,N):\n",
    "        self.u0 = self.u_hat[0]\n",
    "        self.V0 = self.V_hat[0] + np.outer(self.u_hat[0], self.u_hat[0].T) - np.outer(self.u_hat[0], self.u_hat[0].T)\n",
    "\n",
    "        # E[z[n]] : M x 1\n",
    "        # E[z[n]z[n-1].T] : M x M\n",
    "        # E[z[n]z[n].T] : M x M\n",
    "\n",
    "        sub_1 = np.zeros((M,M))\n",
    "        sub_2 = np.array((M,M))\n",
    "        sub_3 = np.array((M,M))\n",
    "        sub_4 = np.array((M,M))\n",
    "        sub_5 = np.array((N,M))\n",
    "        sub_6 = np.array((M,M))\n",
    "        sub_7 = np.array((N,N))\n",
    "        sub_8 = np.array((M,N))\n",
    "        for i in range(1,self.T,1):\n",
    "            print(i,np.dot(self.J[i-1], self.V_hat[i]).shape, np.outer(self.u_hat[i],self.u_hat[i-1].T).shape)\n",
    "            sub_1 += np.dot(self.J[i-1], self.V_hat[i]) + np.outer(self.u_hat[i],self.u_hat[i-1].T) # z[n]z[n-1]\n",
    "            sub_2 += self.V_hat[i-1] + np.outer(self.u_hat[i-1], self.u_hat[i-1].T) # z[n-1]z[n-1]\n",
    "            sub_3 += self.V_hat[i] + np.outer(self.u_hat[i], self.u_hat[i].T) # z[n]z[n]\n",
    "            sub_4 += np.dot(self.J[i-1], self.V_hat[i]) + np.outer(self.u_hat[i-1],self.u_hat[i].T) #z[n-1]z[n]\n",
    "    \n",
    "        for i in range(self.T):\n",
    "            sub_5 += np.outer(self.x[i], self.u_hat[i].T) # x[n]*E[z[n]]\n",
    "            sub_6 += self.V_hat[i] + np.outer(self.u_hat[i], self.u_hat[i].T) # z[n]z[n]\n",
    "            sub_7 += np.outer(self.x[i], self.x[i].T) # x[n]x[n]\n",
    "            sub_8 += np.outer(self.u_hat[i], self.x[i].T) #E[z[n]]*x[n]\n",
    "\n",
    "        self.A = np.dot(sub_1, np.linalg.inv(sub_2))\n",
    "        self.Gamma = 1/(self.N-1) * (sub_3 - np.dot(self.A, sub_4) - np.dot(sub_1, self.A) + np.dot(np.dot(self.A, sub_2), self.A.T))\n",
    "        self.C = np.dot(sub_5, np.linalg.inv(sub_6))\n",
    "        self.Sigma = 1/self.N * (sub_7 - np.dot(self.C, sub_8) - np.dot(sub_5, self.C) + np.dot(np.dot(self.C, sub_6), self.C))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_examples(A, C, Gamma,Sigma,u0,V0,M,N,T):\n",
    " \n",
    "    z = np.zeros((T,M))\n",
    "    x = np.zeros((T,N))\n",
    "    z[0] = np.random.multivariate_normal(u0,V0)\n",
    "    x[0] = np.random.multivariate_normal(np.dot(C,z[0]),Sigma)\n",
    "    for t in range(1,T,1):\n",
    "        z[t] = np.random.multivariate_normal(np.dot(A,z[t-1]),Gamma)\n",
    "        x[t] = np.random.multivariate_normal(np.dot(C,z[t]),Sigma)\n",
    "    return z,x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (2, 2) (2, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bh/px07yp1s5_g3v9q59ynnml900000gn/T/ipykernel_4666/636837028.py:5: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n",
      "  z[0] = np.random.multivariate_normal(u0,V0)\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 46\u001b[0m\n\u001b[1;32m     41\u001b[0m \t\tp_old \u001b[38;5;241m=\u001b[39m p\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 46\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 37\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(kf\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     36\u001b[0m \tkf\u001b[38;5;241m.\u001b[39mbackward(t)\n\u001b[0;32m---> 37\u001b[0m \u001b[43mkf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m p \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mlog(kf\u001b[38;5;241m.\u001b[39mc))\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m>\u001b[39mp_old \u001b[38;5;129;01mand\u001b[39;00m p \u001b[38;5;241m-\u001b[39m p_old \u001b[38;5;241m<\u001b[39m tol:\n",
      "Cell \u001b[0;32mIn[16], line 78\u001b[0m, in \u001b[0;36mKalmanFilter.learning\u001b[0;34m(self, M, N)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(i,np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mJ[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV_hat[i])\u001b[38;5;241m.\u001b[39mshape, np\u001b[38;5;241m.\u001b[39mouter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mu_hat[i],\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mu_hat[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     77\u001b[0m sub_1 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mJ[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV_hat[i]) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mouter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mu_hat[i],\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mu_hat[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;66;03m# z[n]z[n-1]\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m \u001b[43msub_2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mV_hat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mouter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mu_hat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mu_hat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# z[n-1]z[n-1]\u001b[39;00m\n\u001b[1;32m     79\u001b[0m sub_3 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV_hat[i] \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mouter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mu_hat[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mu_hat[i]\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;66;03m# z[n]z[n]\u001b[39;00m\n\u001b[1;32m     80\u001b[0m sub_4 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mJ[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV_hat[i]) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mouter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mu_hat[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mu_hat[i]\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;66;03m#z[n-1]z[n]\u001b[39;00m\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\t\n",
    "\tn_states = 2 # M\n",
    "\tn_obs = 2 # N\n",
    "\tn_time = 100 # T\n",
    "\tp_old = -10000\n",
    "\ttol = 0.01\n",
    "\tmax_iter = 100\n",
    "\n",
    "\t# z: T x M\n",
    "\t# x : T x N\n",
    "\tA = np.array([[0.9, 0.1],[0.5,0.5]])\n",
    "\tC = np.array([[1, 0],[0.2, 0.8]])\n",
    "\t\n",
    "\tGamma = np.array([[0.1, 0.1], [0.1, 0.1]])\n",
    "\tSigma = np.array([[0.5,0.5],[0.5,0.5]])\n",
    "\tu0 = np.array([1,2])\n",
    "\tV0 = np.array([[0.1,0.3],[0.3,0.1]])\n",
    "\n",
    "\tA_init = np.array([[0.5, 0.5],[0.5,0.5]])\n",
    "\tC_init = np.array([[0.5, 0.5],[0.5, 0.5]])\n",
    "\t\n",
    "\tGamma_init = np.array([[0.5, 0.9], [0.9, 4.5]])\n",
    "\tSigma_init = np.array([[0.5, 0.9], [0.9, 4.5]])\n",
    "\tu0_init = np.array([1,2])\n",
    "\tV0_init = np.array([[0.2,0.5],[0.5,0.4]])\n",
    "\n",
    "\n",
    "\tz,x = generate_examples(A,C,Gamma,Sigma,u0,V0,n_states,n_obs,n_time)\n",
    "\tkf = KalmanFilter(A = A_init, C = C_init, Gamma = Gamma_init, Sigma = Sigma_init, u0=u0_init, V0=V0_init,x=x)\n",
    "\t\n",
    "\tfor ite in range(max_iter):\n",
    "\t\tfor t in range(1,kf.T,1):\n",
    "\t\t\tkf.forward(t)\n",
    "\t\tfor t in range(kf.T-2,-1,-1):\n",
    "\t\t\tkf.backward(t)\n",
    "\t\tkf.learning(z.shape[1],x.shape[1])\n",
    "\t\tp = np.sum(np.log(kf.c))\n",
    "\t\tif p>p_old and p - p_old < tol:\n",
    "\t\t\tbreak\n",
    "\t\tp_old = p\n",
    "\t\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
