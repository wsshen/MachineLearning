{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.stats import multivariate_normal,norm\n",
    "# import math\n",
    "# from hmmlearn import hmm\n",
    "# import numpy.random as npr\n",
    "# from pyslds.models import DefaultSLDS\n",
    "    \n",
    "# p_old = -10000\n",
    "# tol = 0.01\n",
    "# max_iter = 500\n",
    "\n",
    "# n_dis = 2               # Number of discrete latent states\n",
    "# n_obs = 2           # Observed data dimension\n",
    "# n_con = 2        # Latent state dimension\n",
    "# D_input = 0         # Exogenous input dimension\n",
    "# n_time = 2000            # Number of time steps to simulate\n",
    "\n",
    "\n",
    "\n",
    "# true_model = DefaultSLDS(n_dis, n_obs, n_con, D_input)\n",
    "# inputs = npr.randn(n_time, D_input)\n",
    "# obs, states_con, states_dis = true_model.generate(n_time, inputs=inputs)\n",
    "# true_ll = true_model.log_likelihood() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a separate model and add the observed data\n",
    "# test_model = DefaultSLDS(n_dis, n_obs, n_con, D_input)\n",
    "# test_model.add_data(obs)\n",
    "\n",
    "# # Run the Gibbs sampler\n",
    "# N_samples = 10000\n",
    "# def update(model):\n",
    "#     model.resample_model()\n",
    "#     return model.log_likelihood()\n",
    "\n",
    "# lls = [update(test_model) for _ in range(N_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the log likelihoods\n",
    "# plt.figure()\n",
    "# plt.plot([0, N_samples], true_ll * np.ones(2), '--k', label=\"true\")\n",
    "# plt.plot(np.arange(N_samples), lls, color='b', label=\"test\")\n",
    "# plt.xlabel(\"iteration\")\n",
    "# plt.ylabel(\"training likelihood\")\n",
    "# plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shen/miniconda3/envs/bayes/lib/python3.12/site-packages/pybasicbayes/distributions/multinomial.py:21: UserWarning: using slow sample_crp_tablecounts\n",
      "  warn('using slow sample_crp_tablecounts')\n",
      "/home/shen/miniconda3/envs/bayes/lib/python3.12/site-packages/pybasicbayes/distributions/negativebinomial.py:25: UserWarning: using slow sample_crp_tablecounts\n",
      "  warn('using slow sample_crp_tablecounts')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from pyslds.models import DefaultSLDS\n",
    "from pylds.util import random_rotation\n",
    "import matplotlib.pyplot as plt\n",
    "K = 2               # Number of discrete latent states\n",
    "D_obs = 2           # Observed data dimension\n",
    "D_latent = 2        # Latent state dimension\n",
    "D_input = 0         # Exogenous input dimension\n",
    "T = 2000            # Number of time steps to simulate\n",
    "\n",
    "true_mu_inits = [np.ones(D_latent) for _ in range(K)]\n",
    "true_sigma_inits = [np.eye(D_latent) for _ in range(K)]\n",
    "true_As = [.9 * random_rotation(D_latent)\n",
    "           for k in range(K)]\n",
    "true_Bs = [3 * npr.randn(D_latent, D_input) for k in range(K)]\n",
    "true_sigma_states = [np.eye(D_latent) for _ in range(K)]\n",
    "true_C = np.random.randn(D_obs, D_latent)\n",
    "true_Ds = np.zeros((D_obs, D_input))\n",
    "true_sigma_obs = np.eye(D_obs)\n",
    "\n",
    "# true_model = DefaultSLDS(K, D_obs, D_latent, D_input=D_input)\n",
    "# inputs = npr.randn(T, D_input)\n",
    "# obs, states_con, states_dis = true_model.generate(T, inputs=inputs)\n",
    "\n",
    "true_model = DefaultSLDS(\n",
    "    K, D_obs, D_latent, D_input=D_input,\n",
    "    mu_inits=true_mu_inits, sigma_inits=true_sigma_inits,\n",
    "    As=true_As, Bs=true_Bs, sigma_statess=true_sigma_states,\n",
    "    Cs=true_C, Ds=true_Ds, sigma_obss=true_sigma_obs)\n",
    "\n",
    "inputs = npr.randn(T, D_input)\n",
    "z = np.arange(K).repeat(T // K)\n",
    "\n",
    "\n",
    "y, x, z = true_model.generate(T, inputs=inputs, stateseq=z)\n",
    "\n",
    "# Compute the log likelihood of the data with the true params\n",
    "true_ll = true_model.log_likelihood() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2, 2) 2000 3\n",
      "(2000, 2, 2) 1999 3\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m     model\u001b[38;5;241m.\u001b[39mresample_model()\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlog_likelihood()\n\u001b[0;32m---> 12\u001b[0m lls \u001b[38;5;241m=\u001b[39m [\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_model\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_samples)]\n",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m, in \u001b[0;36mupdate\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mupdate\u001b[39m(model):\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlog_likelihood()\n",
      "File \u001b[0;32m~/Documents/pyhsmm/pyhsmm/models.py:442\u001b[0m, in \u001b[0;36m_HMMGibbsSampling.resample_model\u001b[0;34m(self, num_procs)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;129m@line_profiled\u001b[39m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mresample_model\u001b[39m(\u001b[38;5;28mself\u001b[39m,num_procs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresample_parameters()\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_procs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_procs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/pyhsmm/pyhsmm/models.py:467\u001b[0m, in \u001b[0;36m_HMMGibbsSampling.resample_states\u001b[0;34m(self, num_procs)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_procs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstates_list:\n\u001b[0;32m--> 467\u001b[0m         \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_joblib_resample_states(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstates_list,num_procs)\n",
      "File \u001b[0;32m~/miniconda3/envs/bayes/lib/python3.12/site-packages/pyslds/states.py:879\u001b[0m, in \u001b[0;36m_SLDSStatesCountData.resample\u001b[0;34m(self, niter)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m itr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(niter):\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresample_discrete_states()\n\u001b[0;32m--> 879\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample_gaussian_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_count_data:\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresample_auxiliary_variables()\n",
      "File \u001b[0;32m~/miniconda3/envs/bayes/lib/python3.12/site-packages/pyslds/states.py:322\u001b[0m, in \u001b[0;36m_SLDSStatesGibbs.resample_gaussian_states\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mresample_gaussian_states\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aBl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# clear any caching\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gaussian_normalizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgaussian_states \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 322\u001b[0m         \u001b[43minfo_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/pylds/pylds/lds_messages_interface.py:66\u001b[0m, in \u001b[0;36m_wrap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/pylds/pylds/lds_messages_interface.py:95\u001b[0m, in \u001b[0;36m_info_argcheck\u001b[0;34m(J_init, h_init, log_Z_init, J_pair_11, J_pair_21, J_pair_22, h_pair_1, h_pair_2, log_Z_pair, J_node, h_node, log_Z_node)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(log_Z_init)\n\u001b[1;32m     94\u001b[0m J_node \u001b[38;5;241m=\u001b[39m _ensure_ndim(J_node, T\u001b[38;5;241m=\u001b[39mT, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 95\u001b[0m J_pair_11, J_pair_21, J_pair_22 \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mmap\u001b[39m(partial(_ensure_ndim, T\u001b[38;5;241m=\u001b[39mT\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m     97\u001b[0m         [J_pair_11, J_pair_21, J_pair_22])\n\u001b[1;32m     98\u001b[0m h_pair_1, h_pair_2 \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28mmap\u001b[39m(partial(_ensure_ndim, T\u001b[38;5;241m=\u001b[39mT\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m    100\u001b[0m         [h_pair_1, h_pair_2])\n\u001b[1;32m    101\u001b[0m log_Z_pair \u001b[38;5;241m=\u001b[39m _ensure_ndim(log_Z_pair, T\u001b[38;5;241m=\u001b[39mT\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/pylds/pylds/lds_messages_interface.py:25\u001b[0m, in \u001b[0;36m_ensure_ndim\u001b[0;34m(X, T, ndim)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m ndim:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape,T,X\u001b[38;5;241m.\u001b[39mndim)\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m T\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a separate model and add the observed data\n",
    "test_model = DefaultSLDS(2*K, D_obs, D_latent, D_input,Cs=npr.randn(D_obs, D_latent),\n",
    "                         Ds=npr.randn(D_obs, D_input))\n",
    "test_model.add_data(y)\n",
    "\n",
    "# Run the Gibbs sampler\n",
    "N_samples = 1000\n",
    "def update(model):\n",
    "    model.resample_model()\n",
    "    return model.log_likelihood()\n",
    "\n",
    "lls = [update(test_model) for _ in range(N_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the log likelihoods\n",
    "plt.figure()\n",
    "plt.plot([0, N_samples], true_ll * np.ones(2), '--k', label=\"true\")\n",
    "plt.plot(np.arange(N_samples), lls, color='b', label=\"test\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"training likelihood\")\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth the data\n",
    "smoothed_data = test_model.smooth(y, inputs)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y, color='b', lw=2, label=\"observed\")\n",
    "plt.plot(smoothed_data, color='k', lw=1, label=\"smoothed\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.xlim(0, 500)\n",
    "plt.ylabel(\"Smoothed Data\")\n",
    "plt.legend(loc=\"upper center\", ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_sigma_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Fancy plotting\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    from hips.plotting.colormaps import gradient_cmap\n",
    "    sns.set_style(\"white\")\n",
    "    sns.set_context(\"paper\")\n",
    "\n",
    "    color_names = [\"red\",\n",
    "                   \"windows blue\",\n",
    "                   \"medium green\",\n",
    "                   \"dusty purple\",\n",
    "                   \"orange\",\n",
    "                   \"amber\",\n",
    "                   \"clay\",\n",
    "                   \"pink\",\n",
    "                   \"greyish\",\n",
    "                   \"light cyan\",\n",
    "                   \"steel blue\",\n",
    "                   \"forest green\",\n",
    "                   \"pastel purple\",\n",
    "                   \"mint\",\n",
    "                   \"salmon\",\n",
    "                   \"dark brown\"]\n",
    "    colors = sns.xkcd_palette(color_names)\n",
    "    cmap = gradient_cmap(colors)\n",
    "except:\n",
    "    from matplotlib.cm import get_cmap\n",
    "    colors = ['b', 'r', 'y', 'g', 'purple']\n",
    "    cmap = get_cmap(\"jet\")\n",
    "\n",
    "\n",
    "from pybasicbayes.util.text import progprint_xrange\n",
    "from pylds.util import random_rotation\n",
    "from pyslds.models import DefaultSLDS\n",
    "\n",
    "npr.seed(0)\n",
    "\n",
    "# Set parameters\n",
    "K = 5\n",
    "D_obs = 1\n",
    "D_latent = 2\n",
    "D_input = 0\n",
    "T = 2000\n",
    "\n",
    "# Make an LDS with known parameters\n",
    "true_mu_inits = [np.ones(D_latent) for _ in range(K)]\n",
    "true_sigma_inits = [np.eye(D_latent) for _ in range(K)]\n",
    "true_As = [.9 * random_rotation(D_latent)\n",
    "           for k in range(K)]\n",
    "true_Bs = [3 * npr.randn(D_latent, D_input) for k in range(K)]\n",
    "true_sigma_states = [np.eye(D_latent) for _ in range(K)]\n",
    "true_C = np.random.randn(D_obs, D_latent)\n",
    "true_Ds = np.zeros((D_obs, D_input))\n",
    "true_sigma_obs = np.eye(D_obs)\n",
    "true_model = DefaultSLDS(\n",
    "    K, D_obs, D_latent, D_input=D_input,\n",
    "    mu_inits=true_mu_inits, sigma_inits=true_sigma_inits,\n",
    "    As=true_As, Bs=true_Bs, sigma_statess=true_sigma_states,\n",
    "    Cs=true_C, Ds=true_Ds, sigma_obss=true_sigma_obs)\n",
    "\n",
    "# Simulate some data with a given discrete state sequence\n",
    "inputs = np.ones((T, D_input))\n",
    "z = np.arange(K).repeat(T // K)\n",
    "y, x, z = true_model.generate(T, inputs=inputs, stateseq=z)\n",
    "\n",
    "# Fit with another LDS.  Give it twice as many states in\n",
    "# order to have some flexibility during inference.\n",
    "test_model = DefaultSLDS(2*K, D_obs, D_latent, D_input,\n",
    "                         Cs=npr.randn(D_obs, D_latent),\n",
    "                         Ds=npr.randn(D_obs, D_input))\n",
    "test_model.add_data(y, inputs=inputs)\n",
    "\n",
    "# Initialize with Gibbs sampler\n",
    "print(\"Initializing with Gibbs\")\n",
    "N_gibbs_samples = 1000\n",
    "def initialize(model):\n",
    "    model.resample_model()\n",
    "    return model.log_likelihood()\n",
    "\n",
    "gibbs_lls = [initialize(test_model) for _ in progprint_xrange(N_gibbs_samples)]\n",
    "\n",
    "# Fit with VBEM\n",
    "# print(\"Fitting with VBEM\")\n",
    "N_vbem_iters = 100\n",
    "def update(model):\n",
    "    model.VBEM_step()\n",
    "    return model.log_likelihood()\n",
    "\n",
    "# test_model._init_mf_from_gibbs()\n",
    "# vbem_lls = [update(test_model) for _ in progprint_xrange(N_vbem_iters)]\n",
    "\n",
    "# Plot the log likelihoods\n",
    "plt.figure(figsize=(5,3))\n",
    "# plt.plot([0, N_gibbs_samples + N_vbem_iters], true_model.log_likelihood() * np.ones(2), '--k', label=\"true\")\n",
    "plt.plot(np.arange(N_gibbs_samples), gibbs_lls, color=colors[0], label=\"gibbs\")\n",
    "# plt.plot(np.arange(N_gibbs_samples + 1, N_gibbs_samples + N_vbem_iters), vbem_lls[1:], color=colors[1], label=\"vbem\")\n",
    "# plt.xlim(0, N_gibbs_samples + N_vbem_iters)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('log likelihood')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"aux/demo_ll.png\")\n",
    "\n",
    "# Smooth the data\n",
    "smoothed_data = test_model.smooth(y, inputs)\n",
    "\n",
    "fig = plt.figure(figsize=(5,3))\n",
    "gs = GridSpec(3, 1, height_ratios=[.1, .1, 1.0])\n",
    "ax = fig.add_subplot(gs[0,0])\n",
    "ax.imshow(true_model.states_list[0].stateseq[None,:], vmin=0, vmax=max(len(colors), true_model.num_states)-1,\n",
    "          cmap=cmap, interpolation=\"nearest\", aspect=\"auto\")\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title(\"True Discrete States\")\n",
    "\n",
    "ax = fig.add_subplot(gs[1,0])\n",
    "ax.imshow(test_model.states_list[0].stateseq[None,:], vmin=0, vmax=max(len(colors), test_model.num_states)-1,\n",
    "          cmap=cmap, interpolation=\"nearest\", aspect=\"auto\")\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title(\"Inferred Discrete States\")\n",
    "\n",
    "ax = fig.add_subplot(gs[2,0])\n",
    "plt.plot(y[:,0], color='k', lw=2, label=\"observed\")\n",
    "plt.plot(smoothed_data[:,0], color=colors[0], lw=1, label=\"smoothed\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.xlim(0, min(T, 500))\n",
    "plt.ylabel(\"Observations\")\n",
    "plt.legend(loc=\"upper center\", ncol=2)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"aux/demo_smooth.png\")\n",
    "\n",
    "plt.figure()\n",
    "from pyhsmm.util.general import rle\n",
    "z_rle = rle(z)\n",
    "offset = 0\n",
    "for k, dur in zip(*z_rle):\n",
    "    plt.plot(x[offset:offset+dur,0], x[offset:offset+dur,1], color=colors[k])\n",
    "    offset += dur\n",
    "\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "plt.title(\"Continuous Latent States\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
