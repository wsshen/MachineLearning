{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal,norm\n",
    "import math\n",
    "from hmmlearn import hmm\n",
    "import numpy.random as npr\n",
    "from pyslds.models import DefaultSLDS\n",
    "from pylds.util import random_rotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM(object):\n",
    "    def __init__(self,K = None, T=None, transition_dis = None, init_prob = None, emission = None, y=None):\n",
    "        \n",
    "        self.y = y # T x N\n",
    "        self.K = K # dimension of hidden discrete states\n",
    "        self.T = T # number of observations\n",
    "        self.N = self.y.shape[1] # dimension of the observations\n",
    "\n",
    "        self.transition_dis = transition_dis # the discrete variable transition probability matrix, K x K\n",
    "        self.init_prob = init_prob # the initial probability of the discrete variable, K\n",
    "        \n",
    "        self.emission = emission # the emission probability of the hidden variable, K x N\n",
    "    \n",
    "    def forward_backward(self, data):\n",
    "        forward_hat = np.zeros((self.T,self.K))\n",
    "        backward_hat = np.zeros((self.T,self.K))\n",
    "        scale_factors = np.zeros((self.T))\n",
    "\n",
    "        forward_hat[0,:] = self.init_prob * self.emission[:,data[0]]\n",
    "        scale_factors[0] = np.sum(forward_hat[0,:])\n",
    "        forward_hat[0,:] = forward_hat[0,:]/scale_factors[0]\n",
    "        \n",
    "        for t in range(self.T-1):\n",
    "            temp = np.matmul(forward_hat[t,:], self.transition) * self.emission[:,data[t+1]] \n",
    "            scale_factors[t+1] = np.sum(temp)\n",
    "            forward_hat[t+1,:] = temp/scale_factors[t+1]\n",
    "\n",
    "        backward_hat[-1,:] = scale_factors[-1]\n",
    "        for t in reversed(range(self.T-1)):\n",
    "            temp = np.matmul(backward_hat[t+1,:] * self.emission[:,data[t+1]], self.transition.T)\n",
    "            backward_hat[t,:] = temp/scale_factors[t]\n",
    "\n",
    "        a = np.zeros((self.T,self.K))\n",
    "        b = np.zeros((self.T,self.K,self.K))\n",
    "        for i in range(self.T):\n",
    "            for j in range(self.K):\n",
    "                a[i,j] = forward_hat[i,j]*backward_hat[i,j]\n",
    "            temp = np.sum(a[i,:])\n",
    "            a[i,:] = a[i,:]/temp\n",
    "\n",
    "        for t in range(self.T-1):\n",
    "            for i in range(self.K):\n",
    "                for j in range(self.K):\n",
    "                    b[t,i,j] = scale_factors[t+1]*forward_hat[t,i]*backward_hat[t+1,j] * self.transition[i,j] * self.emission[j,data[t+1]]\n",
    "\n",
    "        self.a = a\n",
    "        self.b = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class timeVaryingLDS(object):\n",
    "    def __init__(self,T=None, transition_con = None, emission = None, Q = None, R = None, u0 = None, V0 = None, y=None):\n",
    "        \n",
    "        self.y = y # T x N\n",
    "        self.M = transition_con.shape[1] # dimension of hidden continuous states\n",
    "        self.T = T # number of observations\n",
    "        self.N = self.y.shape[1] # dimension of the observations\n",
    "        \n",
    "        self.C = emission # the emission probability of the continuous variable, N x M\n",
    "        self.A = transition_con # the continuous variable transition probability matrix, M x M \n",
    "        \n",
    "        self.Q = Q # Q is the covariance matrix of noise term added to the hidden continuous state transition, M x M\n",
    "        self.R = np.eye(self.N) if R is None else R # R is the covariance matrix of noise term added to the emission, N x N\n",
    "        \n",
    "        self.u0 = u0 # u0 is the initial estimate of the mean of x1, M x 1\n",
    "        self.V0 = V0 # V0 is the initial estimate of the variance of x1, M x M\n",
    "\n",
    "        self.P = np.zeros((self.T, self.M, self.M))\n",
    "        self.P[:,:,:,] = np.eye(self.M)  # P is an intermediate variable during inference, T x M x M\n",
    "        self.u = np.zeros((self.T, self.M)) # T x M x 1\n",
    "        self.V = np.zeros((self.T, self.M, self.M)) # T x M x M\n",
    "        self.K = np.zeros((self.T, self.M, self.N)) # T x M x N\n",
    "        self.c = np.zeros((self.T)) # T x 1\n",
    "\n",
    "        # for backward passing\n",
    "        self.u_hat = np.zeros((self.T, self.M)) # T x M x 1\n",
    "        self.V_hat = np.zeros((self.T, self.M, self.M)) # T x M x M\n",
    "        self.J = np.zeros((self.T, self.M, self.M)) # T x M x M\n",
    "\n",
    "\n",
    "    \n",
    "    def kalman_filtering(self):\n",
    "        # print(self.C.shape,self.u0)\n",
    "        S_temp = np.matmul(np.matmul(self.C, self.V0), self.C.T) + self.R\n",
    "        Q_temp = np.matmul(self.C, self.u0)\n",
    "        I = np.eye(self.M)\n",
    "        \n",
    "        self.V[0] = np.matmul((I - np.matmul(np.matmul(np.matmul(self.V0, self.C.T), np.linalg.inv(S_temp)), self.C)), self.V0)\n",
    "        self.P[0] = np.matmul(np.matmul(self.A, self.V[0]), self.A.T) + self.Q\n",
    "        self.K[0] = np.matmul(np.matmul(self.P[0], self.C.T), np.linalg.inv(np.matmul(np.matmul(self.C, self.P[0]), self.C.T) + self.R))\n",
    "        self.u[0] = self.u0 + np.matmul(self.K[0], self.y[0] - Q_temp)\n",
    "        # print(self.y[0],Q_temp,S_temp)\n",
    "        self.c[0] = multivariate_normal.pdf(self.y[0], Q_temp, S_temp)\n",
    "\n",
    "        for i in range(1,self.T,1):\n",
    "            I = np.eye(self.M)\n",
    "            Q_temp = np.matmul(np.matmul(self.C, self.A), self.u[i-1])\n",
    "            \n",
    "            self.V[i] = np.matmul((I - np.matmul(self.K[i-1], self.C)), self.P[i-1])\n",
    "            self.P[i] = np.matmul(np.matmul(self.A, self.V[i]), self.A.T) + self.Q\n",
    "            S_temp = np.matmul(np.matmul(self.C, self.P[i]), self.C.T) + self.R\n",
    "\n",
    "            self.K[i] = np.matmul(np.matmul(self.P[i], self.C.T), np.linalg.inv(S_temp))\n",
    "\n",
    "            self.u[i] = np.matmul(self.A, self.u[i-1]) + np.matmul(self.K[i-1], self.y[i] - Q_temp)\n",
    "\n",
    "            self.c[i] = multivariate_normal.pdf(self.y[i], Q_temp, S_temp)\n",
    "\n",
    "    def kalman_smoothing(self):\n",
    "\n",
    "        self.u_hat[-1] = self.u[-1]\n",
    "        self.V_hat[-1] = self.V[-1]\n",
    "\n",
    "        for i in range(self.T-2,-1,-1):\n",
    "            # print(self.V[i,k],self.A[k].T,self.P[i,k])\n",
    "            self.J[i] = np.matmul(np.matmul(self.V[i], self.A.T), np.linalg.inv(self.P[i]))\n",
    "            self.u_hat[i] = self.u[i] + np.matmul(self.J[i], self.u_hat[i+1] - np.matmul(self.A, self.u[i]))\n",
    "            self.V_hat[i] = self.V[i] + np.matmul(np.matmul(self.J[i], self.V_hat[i+1] - self.P[i]), self.J[i].T)\n",
    "\n",
    "        sub_1 = np.zeros((self.M,self.M))\n",
    "        sub_2 = np.zeros((self.M,self.M))\n",
    "        sub_3 = np.zeros((self.M,self.M))\n",
    "        sub_4 = np.zeros((self.M,self.M))\n",
    "\n",
    "        sub_5 = np.zeros((self.N,self.M))\n",
    "        sub_6 = np.zeros((self.M,self.M))\n",
    "        sub_7 = np.zeros((self.N,self.N))\n",
    "        sub_8 = np.zeros((self.M,self.N))\n",
    "\n",
    "        for i in range(1,self.T,1):\n",
    "            sub_1 += np.matmul(self.V_hat[i,k],self.J[i-1,k].T) + np.outer(self.u_hat[i,k],self.u_hat[i-1,k].T) # z[n]z[n-1]\n",
    "            \n",
    "            sub_2 += self.V_hat[i-1,k] + np.outer(self.u_hat[i-1,k], self.u_hat[i-1,k].T)\n",
    "\n",
    "            sub_3 += self.V_hat[i,k] + np.outer(self.u_hat[i,k], self.u_hat[i,k].T) # z[n]z[n]\n",
    "            sub_4 += (np.matmul(self.V_hat[i,k],self.J[i-1,k].T) + np.outer(self.u_hat[i,k],self.u_hat[i-1,k].T)).T #z[n-1]z[n]\n",
    "\n",
    "        for i in range(self.T):\n",
    "            sub_5 += a[i,k] * np.outer(self.y[i], self.u_hat[i,k].T) # x[n] * E[z[n]].T\n",
    "            sub_6 += a[i,k] * self.V_hat[i,k] + np.outer(self.u_hat[i,k], self.u_hat[i,k].T) # z[n]z[n]\n",
    "            sub_7 += a[i,k] * np.outer(self.y[i], self.y[i].T) # x[n]x[n]\n",
    "            sub_8 += a[i,k] * np.outer(self.u_hat[i,k], self.y[i].T) #E[z[n]] * x[n].T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLDS(object):\n",
    "    def __init__(self, K = None, T=None, transition_dis = None, init_prob = None, transition_con = None, emission = None, Q = None, R = None, u0 = None, V0 = None, y=None):\n",
    "\n",
    "        if(transition_con is None or transition_dis is None or emission is None):\n",
    "            raise ValueError(\"Set proper system dynamics.\")\n",
    "        self.N = self.y.shape[1]\n",
    "        self.M = transition_con.shape[1]\n",
    "        self.C = emission # the emission probability of the continuous variable, K x N x M\n",
    "        self.A = transition_con # the continuous variable transition probability matrix, K x M x M \n",
    "        \n",
    "        self.Q = Q # Q is the covariance matrix of noise term added to the hidden continuous state transition, K x M x M\n",
    "        self.R = np.eye(self.N) if R is None else R # R is the covariance matrix of noise term added to the emission, K x N x N\n",
    "        \n",
    "        self.u0 = u0 # u0 is the initial estimate of the mean of x1, K x M x 1\n",
    "        self.V0 = V0 # V0 is the initial estimate of the variance of x1, K x M x M\n",
    "        \n",
    "        self.hmm = HMM(K = None, T=None, transition_dis = None, init_prob = None, emission = None, y=None)\n",
    "        R_hat, C_hat, Q_hat, A_hat, V0_hat, u0_hat = self.calculate_effective_con()\n",
    "        self.lds = timeVaryingLDS(T=self.T, transition_con = A_hat, emission = C_hat, Q = Q_hat, R = R_hat, u0 = u0_hat, V0 = V0_hat, y=y)\n",
    "        self.lds.kalman_filtering()\n",
    "        self.lds.kalman_smoothing()\n",
    "\n",
    "    def calculate_effective_con(self):\n",
    "        K = self.hmm.K\n",
    "        T = self.hmm.T\n",
    "        N = self.N\n",
    "        M = self.M\n",
    "\n",
    "        R_hat = np.zeros((T,N,N))# T x N x N\n",
    "        C_hat = np.zeros((T,N,M)) # T x N x M\n",
    "        Q_hat = np.zeros((T, M, M)) # T x M x M\n",
    "        A_hat = np.zeros((T,M,M)) # T x M x M\n",
    "        V0_hat = np.zeros((M,M)) # M x M\n",
    "        u0_hat = np.zeros(M) # M\n",
    "\n",
    "        for t in range(T):\n",
    "            R_hat_inv = np.zeros((N,N))\n",
    "            Q_hat_inv = np.zeros((M,M))\n",
    "            V0_hat_inv = np.zeros(M,M)\n",
    "            for k in range(K):\n",
    "                R_hat_inv += np.linalg.inv(self.R[k])*self.hmm.a[t,k]\n",
    "                C_hat[t] += self.hmm.a[t,k]*np.linalg.inv(self.R[k]) @ C_hat[t]\n",
    "            R_hat[t] = np.linalg.inv(R_hat_inv)\n",
    "            C_hat[t] = R_hat[t] @ C_hat[t]\n",
    "        for k in range(K):\n",
    "            Q_hat_inv += self.hmm.a[-1,k]*self.Q[k] + self.hmm.a[-1,k]*self.C[-1].T @ np.linalg.inv(self.R[k]) @ self.C[k]\n",
    "        Q_hat_inv -= C_hat[-1].T @ np.linalg.inv(R_hat[-1]) @ C_hat[-1]\n",
    "        Q_hat[-1] = np.linalg.inv(Q_hat_inv)\n",
    "        \n",
    "        for k in range(K):\n",
    "            A_hat[-1] += self.hmm.a[-1,k] * np.linalg.inv(self.Q[k]) @ self.A[k]\n",
    "        A_hat[-1] = Q_hat[-1] @ A_hat[-1]\n",
    "        \n",
    "        for t in range(T-2,0,-1):\n",
    "            for k in range(K):\n",
    "                Q_hat_inv += self.hmm.a[t,k]*self.Q[k] + self.hmm.a[t+1,k] * self.A[k].T @ np.linalg.inv(self.Q[k]) @ self.A[k] + self.hmm.a[t,k] * self.C[k].T @ np.linalg.inv(self.R[k]) @ self.C[k]\n",
    "            Q_hat_inv -= A_hat[t+1].T @ np.linalg.inv(Q_hat[t+1]) @ A_hat[t+1] - C_hat[t].T @ np.linalg.inv(R_hat[t]) @ C_hat[t]\n",
    "            Q_hat[t] = np.linalg.inv(Q_hat_inv)\n",
    "            \n",
    "            for k in range(K):\n",
    "                A_hat[t] += self.hmm.a[t,k] * np.linalg.inv(self.Q[k]) @ self.A[k]\n",
    "            A_hat[t] = Q_hat[t] @ A_hat[t]\n",
    "\n",
    "        for k in range(K):\n",
    "            V0_hat_inv += self.hmm.a[0,k]* np.linalg.inv(self.V0[k]) + self.hmm.a[1,k] * self.A[k].T @ np.linalg.inv(self.Q[k]) @ self.A[k] + self.hmm.a[t,k] * self.C[k].T @ np.linalg.inv(self.R[k]) @ self.C[k]\n",
    "        V0_hat_inv -= A_hat[1].T @ np.linalg.inv(Q_hat[1]) @ A_hat[1] - C_hat[0].T @ np.linalg.inv(R_hat[0]) @ C_hat[0]\n",
    "        V0_hat = np.linalg.inv(V0_hat_inv)\n",
    "        \n",
    "        for k in range(K):\n",
    "            u0_hat += self.hmm.a[0,k] * np.linalg.inv(self.V0[k]) @ self.u0[k]\n",
    "        u0_hat = V0_hat @ u0_hat\n",
    "        return R_hat, C_hat, Q_hat, A_hat, V0_hat, u0_hat\n",
    "    \n",
    "    def learning(self):\n",
    "        Sigma = np.zeros((self.N,self.N))\n",
    "        for k in range(self.Z):\n",
    "            self.u0[k] = self.u_hat[0,k]\n",
    "            self.V0[k] = self.V_hat[0,k] + np.outer(self.u_hat[0,k], self.u_hat[0,k].T) - np.outer(self.u_hat[0,k], self.u_hat[0,k].T)\n",
    "\n",
    "            # E[z[n]] : M x 1\n",
    "            # E[z[n]z[n-1].T] : M x M\n",
    "            # E[z[n]z[n].T] : M x M\n",
    "            a = np.zeros((self.T,self.Z))\n",
    "            b = np.zeros((self.T,self.Z,self.Z))\n",
    "            for i in range(self.T):\n",
    "                for j in range(self.Z):\n",
    "                    a[i,j] = self.forward[i,j] * self.backward[i,j]\n",
    "                temp = np.sum(a[i,:])\n",
    "                a[i,:] = a[i,:]/temp\n",
    "\n",
    "            for t in range(self.T - 1):\n",
    "                for i in range(self.Z):\n",
    "                    for j in range(self.Z):\n",
    "                        b[t,i,j] = self.forward[t,i] * self.backward[t+1,j] * self.transition_dis[i,j] * self.q[t+1,i]\n",
    "\n",
    "\n",
    "            sub_1 = np.zeros((self.M,self.M))\n",
    "            sub_2 = np.zeros((self.M,self.M))\n",
    "            sub_3 = np.zeros((self.M,self.M))\n",
    "            sub_4 = np.zeros((self.M,self.M))\n",
    "\n",
    "            sub_5 = np.zeros((self.N,self.M))\n",
    "            sub_6 = np.zeros((self.M,self.M))\n",
    "            sub_7 = np.zeros((self.N,self.N))\n",
    "            sub_8 = np.zeros((self.M,self.N))\n",
    "\n",
    "            for i in range(1,self.T,1):\n",
    "                sub_1 += np.matmul(self.V_hat[i,k],self.J[i-1,k].T) + np.outer(self.u_hat[i,k],self.u_hat[i-1,k].T) # z[n]z[n-1]\n",
    "                \n",
    "                sub_2 += self.V_hat[i-1,k] + np.outer(self.u_hat[i-1,k], self.u_hat[i-1,k].T)\n",
    "\n",
    "                sub_3 += self.V_hat[i,k] + np.outer(self.u_hat[i,k], self.u_hat[i,k].T) # z[n]z[n]\n",
    "                sub_4 += (np.matmul(self.V_hat[i,k],self.J[i-1,k].T) + np.outer(self.u_hat[i,k],self.u_hat[i-1,k].T)).T #z[n-1]z[n]\n",
    "\n",
    "            for i in range(self.T):\n",
    "                sub_5 += a[i,k] * np.outer(self.y[i], self.u_hat[i,k].T) # x[n] * E[z[n]].T\n",
    "                sub_6 += a[i,k] * self.V_hat[i,k] + np.outer(self.u_hat[i,k], self.u_hat[i,k].T) # z[n]z[n]\n",
    "                sub_7 += a[i,k] * np.outer(self.y[i], self.y[i].T) # x[n]x[n]\n",
    "                sub_8 += a[i,k] * np.outer(self.u_hat[i,k], self.y[i].T) #E[z[n]] * x[n].T \n",
    "            \n",
    "\n",
    "            self.transition_con[k] = np.matmul(sub_1, np.linalg.inv(sub_2))\n",
    "            temp = 1/(self.T-1) * (sub_3 - np.matmul(self.transition_con[k],sub_4) - np.matmul(sub_1,self.transition_con[k].T) + np.matmul(np.matmul(self.transition_con[k],sub_2),self.transition_con[k].T))\n",
    "            # self.Gamma[k] = 1/(self.T-1) * (sub_3 - np.matmul(self.transition_con[k],sub_4) - np.matmul(sub_1,self.transition_con[k].T) + np.matmul(np.matmul(self.transition_con[k],sub_2),self.transition_con[k].T))\n",
    "            # print(self.Gamma[k].shape,temp.shape)\n",
    "            # print(self.Gamma)\n",
    "\n",
    "            self.emission[k] = np.matmul(sub_5, np.linalg.inv(sub_6))\n",
    "            Sigma += 1/self.T * (sub_7 - np.matmul(self.emission[k],sub_8) - np.matmul(sub_5,self.emission[k].T) + \n",
    "                                 np.matmul(np.matmul(self.emission[k],sub_6),self.emission[k].T))\n",
    "            self.Sigma = Sigma / self.Z\n",
    "\n",
    "\n",
    "\n",
    "            for i in range(self.Z):\n",
    "                for j in range(self.Z):\n",
    "                    self.transition_dis[i,j] = np.sum(b[0:-1,i,j])/np.sum(b[0:-1,i,:])\n",
    "\n",
    "            for i in range(self.Z):\n",
    "                self.init_prob[i] = a[0,i]/np.sum(a[0,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\t\n",
    "\t# n_dis = 2 # Z\n",
    "\t# n_con = 2 # M\n",
    "\t# self.T = 2 # N\n",
    "\t# n_time = 400 # T\n",
    "\n",
    "\t# transition_dis = np.array([[0.95,0.05],[0.05,0.95]]) # the discrete variable transition probability matrix, Z x Z\n",
    "\t# init_prob = np.array([0.4,0.6]) # the initial probability of the discrete variable, N\n",
    "\t\n",
    "\t# emission = np.array([[[0.5, 0.5],[0.1, 0.9]],[[0.2, 0.8],[0.9, 0.1]]]) # the emission probability of the continuous variable, Z x N x M\n",
    "\n",
    "\t# transition_con = np.array([[[0.9, 0.1],[0.1, 0.9]],[[0.1, 0.9],[0.1, 0.9]]]) # the continuous variable transition probability matrix, Z x M x M \n",
    "\t\n",
    "\t# Gamma = np.array([[[0.1, 0.3],[0.3, 0.1]],[[1, 0.5],[0.5, 1]]]) # Gamma is the covariance matrix of noise term added to the hidden state transition, Z x M x M\n",
    "\t# Sigma = np.array([[0.2, 0.8],[0.8, 0.2]]) # Sigma is the covariance matrix of noise term added to the emission, N x N\n",
    "\t# x0 = np.array([[0.2,0.2],[0.5, 0.5]]) # N x M\n",
    "\n",
    "\n",
    "\n",
    "\t# states_dis, states_con,obs = generate_examples(T=n_time, Z = n_dis, M = n_con, N = self.T, transition_dis = transition_dis, init_prob = init_prob, \n",
    "\t# \t\t\t\t\t\t\t\t\t\t\ttransition_con = transition_con, emission = emission, Gamma = Gamma, Sigma = Sigma, x0 = x0)\n",
    "\t\n",
    "\n",
    "\tp_old = -10000\n",
    "\ttol = 0.01\n",
    "\tmax_iter = 10\n",
    "\t\n",
    "\n",
    "\n",
    "\tn_dis = 2               # Number of discrete latent states\n",
    "\tself.T = 2           # Observed data dimension\n",
    "\tn_con = 2        # Latent state dimension\n",
    "\tD_input = 0         # Exogenous input dimension\n",
    "\tn_time = 2000            # Number of time steps to simulate\n",
    "\t# K = 2               # Number of discrete latent states\n",
    "\t# self.T = 2           # Observed data dimension\n",
    "\t# n_con = 2        # Latent state dimension\n",
    "\t# D_input = 0         # Exogenous input dimension\n",
    "\t# T = 2000            # Number of time steps to simulate\n",
    "\n",
    "\ttrue_mu_inits = [np.ones(n_con) for _ in range(n_dis)]\n",
    "\ttrue_sigma_inits = [np.eye(n_con) for _ in range(n_dis)]\n",
    "\ttrue_As = [.9 * random_rotation(n_con)\n",
    "\t\t\tfor k in range(n_dis)]\n",
    "\ttrue_Bs = [3 * npr.randn(n_con, D_input) for k in range(n_dis)]\n",
    "\ttrue_sigma_states = [np.eye(n_con) for _ in range(n_dis)]\n",
    "\ttrue_C = np.random.randn(self.T, n_con)\n",
    "\ttrue_Ds = np.zeros((self.T, D_input))\n",
    "\ttrue_sigma_obs = np.eye(self.T)\n",
    "\n",
    "\ttrue_model = DefaultSLDS(n_dis, self.T, n_con, D_input,mu_inits=true_mu_inits, sigma_inits=true_sigma_inits,\n",
    "\t\tAs=true_As, Bs=true_Bs, sigma_statess=true_sigma_states,\n",
    "\t\tCs=true_C, Ds=true_Ds, sigma_obss=true_sigma_obs)\n",
    "\t\n",
    "\tinputs = npr.randn(n_time, D_input)\n",
    "\tz = np.arange(n_dis).repeat(n_time // n_dis)\n",
    "\n",
    "\tobs, states_con, states_dis = true_model.generate(n_time, inputs=inputs, stateseq=z)\n",
    "\t# print(obs.shape,states_con.shape,states_dis.shape)\n",
    "\n",
    "\ttransition_dis_init = np.array([[0.7,0.3],[0.3,0.7]]) \n",
    "\tinit_prob_init = np.array([0.9,0.1]) \n",
    "\t\n",
    "\temission_init = np.array([[[0.3, 0.7],[0.2, 0.8]],[[0.25, 0.75],[0.4, 0.6]]]) \n",
    "\ttransition_con_init = np.array([[[0.9, 0.1],[0.1, 0.9]],[[0.1, 0.9],[0.1, 0.9]]])\n",
    "\t\n",
    "\tGamma_init = np.array([[[1.0, 0],[0, 1.0]],[[1.0, 0],[0, 1.0]]])  \n",
    "\tSigma_init = np.array([[1.0, 0],[0, 1.0]])\n",
    "\tu0 = np.array([[0.3, 0.3],[0.5, 0.5]]) # Z x M x 1\n",
    "\tV0 = Gamma_init # Z x M x M\n",
    "\n",
    "\tslds = SLDS(Z = n_dis, T=n_time, transition_dis = transition_dis_init, init_prob = init_prob_init, transition_con = transition_con_init, \n",
    "\t\t\t emission = emission_init, Gamma = Gamma_init, Sigma = Sigma_init, u0 = u0, V0 = V0, y=obs)\n",
    "\t\n",
    "\tfor ite in range(max_iter):\n",
    "\t\n",
    "\t\t# print(slds.forward,slds.backward)\n",
    "\t\t# print(slds.q,slds.h)\n",
    "\t\tslds.kalman_filtering()\n",
    "\t\tslds.kalman_smoothing()\n",
    "\t\tslds.forward_backward()\n",
    "\t\tslds.learning()\n",
    "\n",
    "\t\tp = np.sum(np.log(slds.c))\n",
    "\t\tprint(f'The current iteration is: {ite}. The likelihood is {p}',end='\\r')\n",
    "\t\tif p>p_old and p - p_old < tol:\n",
    "\t\t\tbreak\n",
    "\t\tp_old = p\n",
    "\n",
    "\tprint('u0\\n',slds.u0,'\\nV0\\n',slds.V0,'\\ntransition_dis\\n',slds.transition_dis,'\\ntransition_con\\n',slds.transition_con,'\\nemission\\n',slds.emission,'\\nGamma\\n',\n",
    "\t   slds.Gamma,'\\ninit_prob\\n',slds.init_prob,'\\nGamma\\n',slds.Gamma,'\\nSigma\\n',slds.Sigma)\n",
    "\treturn slds,states_dis,states_con,obs\n",
    "\n",
    "slds,states_dis,states_con,obs = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(5,0,-1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
