{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/Users/shenwang/Documents/CIFAR/cifar-10-python/cifar-10-batches-py'\n",
    "data_prefix = 'data'\n",
    "test_prefix = 'test'\n",
    "num_channels = 3\n",
    "\n",
    "training_files = glob.glob(directory+os.sep+data_prefix+'*')\n",
    "test_files = glob.glob(directory+os.sep+test_prefix+'*')\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def changeDimension(x):\n",
    "    \n",
    "    assert isinstance(x,list),'x must be list type'\n",
    "    np_x = np.array(x)\n",
    "    # print(np_x.shape)\n",
    "    sp = np_x.shape\n",
    "    size_per_channel = sp[-1]/num_channels\n",
    "    len_per_side = int(np.sqrt(size_per_channel))\n",
    "    if len(sp) == 2:\n",
    "        new_array = np.reshape(np_x,(sp[0]*sp[1]))\n",
    "    if len(sp) == 3:\n",
    "        new_array = np.reshape(np_x,(sp[0]*sp[1],num_channels,len_per_side,len_per_side))\n",
    "        # sp_new = output.shape\n",
    "        # new_array = np.zeros((sp_new[0],sp_new[2],sp_new[3],sp_new[1]))\n",
    "        # for i in range(sp_new[0]):\n",
    "        #     for j in range(sp_new[1]):\n",
    "        #         new_array[i,:,:,j] = output[i,j,:,:]\n",
    "\n",
    "    return new_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(x,c_x=28,c_y=28,normalize=True,center_crop=True,whitening=True):\n",
    "    sp = x.shape\n",
    "    assert len(sp) == 4, 'The input shape must be number_of_frames * number_of_channels * len_of_image * len_of_image'\n",
    "    len_x = sp[2]\n",
    "    len_y = sp[3]\n",
    "    start_x = (len_x - c_x)//2\n",
    "    stop_x = start_x + c_x\n",
    "    start_y = (len_y-c_y)//2\n",
    "    stop_y = start_y + c_y\n",
    "    new_x = np.zeros((sp[0],sp[1],c_x,c_y))\n",
    "\n",
    "\n",
    "    for i in range(sp[0]):\n",
    "        for j in range(sp[1]):\n",
    "            if normalize:\n",
    "                image = x[i,:,:,j]/255\n",
    "            else:\n",
    "                image = x[i,:,:,j]\n",
    "            if center_crop:\n",
    "                new_x[i,:,:,j] = image[start_x:stop_x,start_y:stop_y]\n",
    "            else:\n",
    "                new_x[i,:,:,j] = image\n",
    "\n",
    "            if whitening:\n",
    "                temp = image[start_x:stop_x,start_y:stop_y]\n",
    "                mean = np.mean(temp)\n",
    "                std = np.std(temp)\n",
    "                std_mod = max(std,1/np.sqrt(np.size(temp)))\n",
    "                new_x[i,:,:,j] = (temp - mean)/std_mod\n",
    "            \n",
    "    return new_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_raw_images = []\n",
    "training_labels = []\n",
    "\n",
    "test_raw_images = []\n",
    "test_labels = []\n",
    "\n",
    "for file in training_files:\n",
    "    batch_dict = unpickle(file)\n",
    "    training_raw_images.append(batch_dict[b'data'])\n",
    "    training_labels.append(batch_dict[b'labels'])\n",
    "for file in test_files:\n",
    "    batch_dict = unpickle(file)\n",
    "    test_raw_images.append(batch_dict[b'data'])\n",
    "    test_labels.append(batch_dict[b'labels'])\n",
    "\n",
    "training_raw_images = changeDimension(training_raw_images)\n",
    "training_labels = changeDimension(training_labels)\n",
    "test_raw_images = changeDimension(test_raw_images)\n",
    "test_labels = changeDimension(test_labels)\n",
    "\n",
    "training_images = preprocessing(training_raw_images)\n",
    "test_images = preprocessing(test_raw_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR(Dataset):\n",
    "    def __init__(self,data,label):\n",
    "        super(CIFAR,self).__init__()\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx,:,:,:], self.label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(nn.Module):\n",
    "    def __init__(self,input_channel,output_channel,kernel_size,stride,padding):\n",
    "        super(Conv, self).__init__()\n",
    "        self.conv = nn.Conv2d(input_channel, output_channel, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.batchnorm = nn.BatchNorm2d(output_channel) \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, input_channel, output1, output3):\n",
    "        super(Inception,self).__init__()\n",
    "        self.branch1 = Conv(input_channel, output1, 1, 1,padding=0)\n",
    "        self.branch3 = Conv(input_channel, output3, 3, 1,padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b1 = self.branch1(x)  \n",
    "        b3 = self.branch3(x) \n",
    "        # print(b1.shape,b3.shape)\n",
    "        # Concatenate along the channel dimension\n",
    "        return torch.cat([b1, b3], dim=1)\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, input_channel, output_channel):\n",
    "        super(Downsample,self).__init__()\n",
    "        self.branch_conv = Conv(input_channel, output_channel, 3, 2,padding=1)\n",
    "        self.branch_pool = nn.MaxPool2d(3, stride=2,padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b_conv = self.branch_conv(x)  \n",
    "        b_pool = self.branch_pool(x) \n",
    "        # print(b_conv.shape,b_pool.shape)\n",
    "        # Concatenate along the channel dimension\n",
    "        return torch.cat([b_conv, b_pool], dim=1)\n",
    "\n",
    "class InceptionSmall(nn.Module):\n",
    "    def __init__(self,input_channel):\n",
    "        super(InceptionSmall, self).__init__()\n",
    "        self.initial_conv = Conv(input_channel, 96, 3, 1,1)  \n",
    "\n",
    "        # First Inception Block\n",
    "        self.inception1 = Inception(96, 32, 32)\n",
    "        self.inception2 = Inception(64, 32, 48)\n",
    "        self.downsample1 = Downsample(80, 80)\n",
    "\n",
    "        # Second Inception Block\n",
    "        self.inception3 = Inception(160, 112, 48)\n",
    "        self.inception4 = Inception(160, 96, 64)\n",
    "        self.inception5 = Inception(160, 80, 80)\n",
    "        self.inception6 = Inception(160, 48, 96)\n",
    "        self.downsample2 = Downsample(144, 96)\n",
    "\n",
    "        # Final Inception Block\n",
    "        self.inception7 = Inception(240, 176, 160)\n",
    "        self.inception8 = Inception(336, 176, 160)\n",
    "\n",
    "        # Classification Head\n",
    "        self.global_pool = nn.AvgPool2d(7)  # 7x7 kernel global pooling\n",
    "        self.fc = nn.Linear(336, 10)  # 10-way classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial_conv(x)\n",
    "        # print('initial_conv done')\n",
    "        x = self.inception1(x)\n",
    "        # print('inception1 done')\n",
    "        x = self.inception2(x)\n",
    "        # print('inception2 done')\n",
    "\n",
    "        x = self.downsample1(x)\n",
    "        # print('downsample1 done')\n",
    "        x = self.inception3(x)\n",
    "        # print('inception3 done')\n",
    "\n",
    "        x = self.inception4(x)\n",
    "        # print('inception4 done')\n",
    "\n",
    "        x = self.inception5(x)\n",
    "        # print('inception5 done')\n",
    "\n",
    "        x = self.inception6(x)\n",
    "        # print('inception6 done')\n",
    "\n",
    "        x = self.downsample2(x)\n",
    "        # print('downsample2 done',x.shape)\n",
    "        x = self.inception7(x)\n",
    "        # print('inception7 done')\n",
    "\n",
    "        x = self.inception8(x)\n",
    "        # print('inception8 done')\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        # print('global_pool done')\n",
    "        # print(x.shape)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer,device):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        # print(batch,X.shape,y.shape)\n",
    "        X,y = X.to(device),y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn,device):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X,y = X.to(device),y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "batch_size = 64\n",
    "epochs = 25000\n",
    "momentum = 0.9\n",
    "weight_decay = 0.95\n",
    "\n",
    "data_train = CIFAR(torch.tensor(training_images,dtype=torch.float32),torch.tensor(training_labels,dtype=torch.long))\n",
    "data_test = CIFAR(torch.tensor(test_images,dtype=torch.float32),torch.tensor(test_labels,dtype=torch.long))\n",
    "\n",
    "train_dataloader = DataLoader(data_train, batch_size= batch_size)\n",
    "test_dataloader = DataLoader(data_test, batch_size=batch_size)\n",
    "\n",
    "model = InceptionSmall(3).to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,momentum=momentum)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.356857  [   64/50000]\n",
      "loss: 2.114672  [ 6464/50000]\n",
      "loss: 1.999472  [12864/50000]\n",
      "loss: 2.142463  [19264/50000]\n",
      "loss: 2.172346  [25664/50000]\n",
      "loss: 2.002348  [32064/50000]\n",
      "loss: 2.035090  [38464/50000]\n",
      "loss: 1.958720  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 25.6%, Avg loss: 2.069321 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.052804  [   64/50000]\n",
      "loss: 1.924896  [ 6464/50000]\n",
      "loss: 1.859381  [12864/50000]\n",
      "loss: 2.060254  [19264/50000]\n",
      "loss: 1.961628  [25664/50000]\n",
      "loss: 1.881349  [32064/50000]\n",
      "loss: 1.968502  [38464/50000]\n",
      "loss: 1.906920  [44864/50000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     test_loop(test_dataloader, model, loss_fn,device)\n\u001b[1;32m      7\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[9], line 14\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.12/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.12/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.12/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer,device)\n",
    "    \n",
    "    test_loop(test_dataloader, model, loss_fn,device)\n",
    "    scheduler.step()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Define the Inception block\n",
    "# class InceptionBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, ch1x1, ch3x3reduce, ch3x3, ch5x5reduce, ch5x5, pool_proj):\n",
    "#         super(InceptionBlock, self).__init__()\n",
    "\n",
    "#         # 1x1 Convolution\n",
    "#         self.branch1x1 = nn.Conv2d(in_channels, ch1x1, kernel_size=1)\n",
    "\n",
    "#         # 1x1 followed by 3x3 Convolution\n",
    "#         self.branch3x3 = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels, ch3x3reduce, kernel_size=1),\n",
    "#             nn.Conv2d(ch3x3reduce, ch3x3, kernel_size=3, padding=1)\n",
    "#         )\n",
    "\n",
    "#         # 1x1 followed by 5x5 Convolution\n",
    "#         self.branch5x5 = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels, ch5x5reduce, kernel_size=1),\n",
    "#             nn.Conv2d(ch5x5reduce, ch5x5, kernel_size=5, padding=2)\n",
    "#         )\n",
    "\n",
    "#         # MaxPooling followed by 1x1 Convolution\n",
    "#         self.branch_pool = nn.Sequential(\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "#             nn.Conv2d(in_channels, pool_proj, kernel_size=1)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         branch1x1 = self.branch1x1(x)\n",
    "#         branch3x3 = self.branch3x3(x)\n",
    "#         branch5x5 = self.branch5x5(x)\n",
    "#         branch_pool = self.branch_pool(x)\n",
    "\n",
    "#         # Concatenate along the channel dimension\n",
    "#         outputs = torch.cat([branch1x1, branch3x3, branch5x5, branch_pool], dim=1)\n",
    "#         return outputs\n",
    "\n",
    "# # Define the complete Inception Network (simplified version)\n",
    "# class InceptionNet(nn.Module):\n",
    "#     def __init__(self, num_classes=10):\n",
    "#         super(InceptionNet, self).__init__()\n",
    "\n",
    "#         # Initial convolution and pooling layers\n",
    "#         self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "#         self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "#         # Inception blocks\n",
    "#         self.inception1 = InceptionBlock(64, 64, 96, 128, 16, 32, 32)\n",
    "#         self.inception2 = InceptionBlock(256, 128, 128, 192, 32, 96, 64)\n",
    "\n",
    "#         # Global average pooling and fully connected layer\n",
    "#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "#         self.fc = nn.Linear(480, num_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         x = self.maxpool1(x)\n",
    "\n",
    "#         x = self.inception1(x)\n",
    "#         x = self.inception2(x)\n",
    "\n",
    "#         x = self.avgpool(x)\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = self.fc(x)\n",
    "#         return x\n",
    "\n",
    "# # Instantiate the network\n",
    "# model = InceptionNet(num_classes=10)\n",
    "\n",
    "# # Print the model summary\n",
    "# print(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
