{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/Users/shenwang/Documents/CIFAR/cifar-10-python/cifar-10-batches-py'\n",
    "data_prefix = 'data'\n",
    "test_prefix = 'test'\n",
    "num_channels = 3\n",
    "\n",
    "training_files = glob.glob(directory+os.sep+data_prefix+'*')\n",
    "test_files = glob.glob(directory+os.sep+test_prefix+'*')\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def changeDimension(x):\n",
    "    \n",
    "    assert isinstance(x,list),'x must be list type'\n",
    "    np_x = np.array(x)\n",
    "    # print(np_x.shape)\n",
    "    sp = np_x.shape\n",
    "    size_per_channel = sp[-1]/num_channels\n",
    "    len_per_side = int(np.sqrt(size_per_channel))\n",
    "    if len(sp) == 2:\n",
    "        new_array = np.reshape(np_x,(sp[0]*sp[1]))\n",
    "    if len(sp) == 3:\n",
    "        new_array = np.reshape(np_x,(sp[0]*sp[1],num_channels,len_per_side,len_per_side))\n",
    "        # sp_new = output.shape\n",
    "        # new_array = np.zeros((sp_new[0],sp_new[2],sp_new[3],sp_new[1]))\n",
    "        # for i in range(sp_new[0]):\n",
    "        #     for j in range(sp_new[1]):\n",
    "        #         new_array[i,:,:,j] = output[i,j,:,:]\n",
    "\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(x,c_x=28,c_y=28,normalize=True,center_crop=True,whitening=True):\n",
    "    sp = x.shape\n",
    "    assert len(sp) == 4, 'The input shape must be number_of_frames * number_of_channels * len_of_image * len_of_image'\n",
    "    len_x = sp[2]\n",
    "    len_y = sp[3]\n",
    "    start_x = (len_x - c_x)//2\n",
    "    stop_x = start_x + c_x\n",
    "    start_y = (len_y-c_y)//2\n",
    "    stop_y = start_y + c_y\n",
    "    new_x = np.zeros((sp[0],sp[1],c_x,c_y))\n",
    "\n",
    "\n",
    "    for i in range(sp[0]):\n",
    "        for j in range(sp[1]):\n",
    "            if normalize:\n",
    "                image = x[i,j,:,:]/255\n",
    "            else:\n",
    "                image = x[i,j,:,:]\n",
    "            if center_crop:\n",
    "                new_x[i,j,:,:] = image[start_x:stop_x,start_y:stop_y]\n",
    "            else:\n",
    "                new_x[i,j,:,:] = image\n",
    "\n",
    "            if whitening:\n",
    "                temp = image[start_x:stop_x,start_y:stop_y]\n",
    "                mean = np.mean(temp)\n",
    "                std = np.std(temp)\n",
    "                std_mod = max(std,1/np.sqrt(np.size(temp)))\n",
    "                new_x[i,j,:,:] = (temp - mean)/std_mod\n",
    "            \n",
    "    return new_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_raw_images = []\n",
    "training_labels = []\n",
    "\n",
    "test_raw_images = []\n",
    "test_labels = []\n",
    "\n",
    "for file in training_files:\n",
    "    batch_dict = unpickle(file)\n",
    "    training_raw_images.append(batch_dict[b'data'])\n",
    "    training_labels.append(batch_dict[b'labels'])\n",
    "for file in test_files:\n",
    "    batch_dict = unpickle(file)\n",
    "    test_raw_images.append(batch_dict[b'data'])\n",
    "    test_labels.append(batch_dict[b'labels'])\n",
    "\n",
    "training_raw_images = changeDimension(training_raw_images)\n",
    "training_labels = changeDimension(training_labels)\n",
    "test_raw_images = changeDimension(test_raw_images)\n",
    "test_labels = changeDimension(test_labels)\n",
    "\n",
    "training_images = preprocessing(training_raw_images)\n",
    "test_images = preprocessing(test_raw_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR(Dataset):\n",
    "    def __init__(self,data,label):\n",
    "        super(CIFAR,self).__init__()\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx,:,:,:], self.label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(nn.Module):\n",
    "    def __init__(self,input_channel,output_channel,kernel_size,stride,padding):\n",
    "        super(Conv, self).__init__()\n",
    "        self.conv = nn.Conv2d(input_channel, output_channel, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.max = nn.MaxPool2d(3, stride=2,padding=0)\n",
    "        self.localnorm = nn.LocalResponseNorm(5,alpha=1e-4,beta=0.75,k=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.max(x)\n",
    "        x = self.localnorm(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "class AlexnetSmall(nn.Module):\n",
    "    def __init__(self,input_channel):\n",
    "        super(AlexnetSmall, self).__init__()\n",
    "        self.initial_conv = Conv(input_channel, 96, 3, 1,1)  \n",
    "\n",
    "\n",
    "\n",
    "        self.fc = nn.Linear(336, 10)  # 10-way classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial_conv(x)\n",
    "        # print('initial_conv done')\n",
    "\n",
    "\n",
    "        x = self.inception4(x)\n",
    "        # print('inception4 done')\n",
    "\n",
    "        x = self.inception5(x)\n",
    "        # print('inception5 done')\n",
    "\n",
    "        x = self.inception6(x)\n",
    "        # print('inception6 done')\n",
    "\n",
    "        x = self.downsample2(x)\n",
    "        # print('downsample2 done',x.shape)\n",
    "        x = self.inception7(x)\n",
    "\n",
    "\n",
    "        x = self.inception8(x)\n",
    " \n",
    "\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "momentum = 0.9\n",
    "weight_decay = 0.95\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer,device):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    num_batches = len(dataloader)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        # print(batch,X.shape,y.shape)\n",
    "        X,y = X.to(device),y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    train_loss/=num_batches\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn,device):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X,y = X.to(device),y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return correct,test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_train = CIFAR(torch.tensor(training_images,dtype=torch.float32),torch.tensor(training_labels,dtype=torch.long))\n",
    "data_test = CIFAR(torch.tensor(test_images,dtype=torch.float32),torch.tensor(test_labels,dtype=torch.long))\n",
    "\n",
    "train_dataloader = DataLoader(data_train, batch_size= batch_size,shuffle=True,num_workers=0,pin_memory=True)\n",
    "test_dataloader = DataLoader(data_test, batch_size=batch_size,shuffle=True, num_workers=0,pin_memory=True)\n",
    "\n",
    "model = InceptionSmall(3).to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,momentum=momentum)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "\n",
    "    train_loss = train_loop(train_dataloader, model, loss_fn, optimizer,device)\n",
    "    \n",
    "    test_correct, test_loss = test_loop(test_dataloader, model, loss_fn,device)\n",
    "    scheduler.step()\n",
    "    current_time = time.time()\n",
    "    elapsed_time = current_time - start_time\n",
    "    print(f'elapsed time is:{elapsed_time} seconds')\n",
    "    if t % 50 ==0:\n",
    "        torch.save(model.state_dict(), directory + os.sep + 'model' + os.sep +'model_weights'+str(t)+'.pth')\n",
    "    if t % 10==0:\n",
    "        print(f'saving running results')\n",
    "    with open(directory + os.sep + 'model' + os.sep + 'file' + str(t) +'.pkl', 'wb') as file:\n",
    "        pickle.dump([train_loss,test_correct,test_loss], file)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
