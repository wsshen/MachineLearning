{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal,beta,dirichlet, norm\n",
    "from math import log\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "np.random.seed(1234)\n",
    "from scipy.special import gamma\n",
    "import ternary\n",
    "\n",
    "\n",
    "np.set_printoptions(formatter={'all':lambda x: '%.3f' % x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 100\n",
    "x1 = norm.rvs(-2,1,size=sz)\n",
    "x2 = norm.rvs(2,1,size=sz)\n",
    "x3 = norm.rvs(6,1,size=sz)\n",
    "x = np.hstack((x1,x2,x3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x,bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_id = np.zeros(x.shape)\n",
    "clusters,cluster_counts = np.unique(c_id,return_counts=True)\n",
    "n_cluster = len(clusters)\n",
    "\n",
    "sigma0 = 1\n",
    "mu0 = 0\n",
    "\n",
    "# sigma_cluster = np.array([sigma0])\n",
    "# mu_cluster = np.array([mu0])\n",
    "\n",
    "sigma_y = 1\n",
    "tau_y = 1/(sigma_y**2)\n",
    "ite = 3\n",
    "alpha = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rand_x = p0.rvs(size=2*sz)\n",
    "\n",
    "# rand_x_prob = dirichlet.pdf(rand_x,size=2*sz)\n",
    "\n",
    "# pred_x = norm.rvs(rand_x,sigma0,size=2*sz) * rand_x_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in range(ite):\n",
    "    for i in range(sz*2):\n",
    "        print(\"Before calculating-------------------------------------------\")\n",
    "        print(f\"cluster counts is:{cluster_counts}\")\n",
    "        print(f\"number of cluster is {n_cluster}\")\n",
    "        assign_id = int(c_id[i])\n",
    "        cluster_counts[assign_id] -= 1\n",
    "        # print(f\"cluster counts after minus 1 is:{cluster_counts}\")\n",
    "        if cluster_counts[assign_id] == 0:\n",
    "            cluster_counts[assign_id] = cluster_counts[-1]\n",
    "            # print(f\"cluster counts after switching the last cluster element:{cluster_counts}\")\n",
    "            c_id[np.where(c_id==n_cluster-1)[0]] = assign_id\n",
    "            cluster_counts = np.delete(cluster_counts, n_cluster-1) \n",
    "            # print(f\"cluster counts after deleting the last cluster:{cluster_counts}\")\n",
    "            n_cluster -= 1\n",
    "        c_id[i] = -1\n",
    "\n",
    "        # print(f\"This is the {it} iteration, and the {i}th element. The {assign_id}th element in the c_id\")\n",
    "        # print(f\"After calculating-------------------------\")\n",
    "        # print(f\"cluster counts is:{cluster_counts}\")\n",
    "        # print(f\"number of cluster is {n_cluster}\")\n",
    "\n",
    "        logp = np.zeros((n_cluster+1))\n",
    "        for j in range(n_cluster):\n",
    "\n",
    "            idx = np.where(c_id == j)[0] # element indices within clusters[j]\n",
    "            y_average = np.mean(x[idx])\n",
    "            prior_tau_j = 1/(sigma0**2)\n",
    "            mu_j = (y_average*cluster_counts[j]* tau_y + mu0 * prior_tau_j )/ (cluster_counts[j]* tau_y + prior_tau_j )\n",
    "            sigma_j = np.sqrt(1/(cluster_counts[j]* tau_y + prior_tau_j ) + sigma_y**2)\n",
    "            \n",
    "            logp[j] = np.log(cluster_counts[j]/(sz*2-1+alpha)) + norm.logpdf(x[i],mu_j,sigma_j)\n",
    "        new_cluster_mu = mu0\n",
    "        new_cluster_sigma = np.sqrt(sigma0**2+sigma_y**2)\n",
    "        \n",
    "        logp[-1] = np.log(alpha/(sz*2-1+alpha)) + norm.logpdf(x[i],new_cluster_mu,new_cluster_sigma)\n",
    "        print(f\"logp is:{logp}\")\n",
    "        logp_max = np.max(logp)\n",
    "        logp = logp - logp_max\n",
    "        p = np.exp(logp)\n",
    "        p = p/np.sum(p)\n",
    "        print(f\"p is:{p}\")        \n",
    "        new_c = np.random.choice(np.arange(n_cluster+1),p=p)\n",
    "        # print(f\"new class is : {new_c}\")\n",
    "        if new_c == n_cluster:\n",
    "            # clusters = np.append(clusters,new_c)\n",
    "            n_cluster += 1\n",
    "            cluster_counts = np.append(cluster_counts,1)\n",
    "        else:\n",
    "            cluster_counts[new_c] += 1\n",
    "        c_id[i] = new_c\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_j = np.zeros((n_cluster))\n",
    "for j in range(n_cluster):\n",
    "\n",
    "    idx = np.where(c_id == j)[0] # element indices within clusters[j]\n",
    "    y_average = np.mean(x[idx])\n",
    "    prior_tau_j = 1/(sigma0**2)\n",
    "    mu_j[j] = (y_average*cluster_counts[j]* tau_y + mu0 * prior_tau_j )/ (cluster_counts[j]* tau_y + prior_tau_j )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mu_j)\n",
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(mu_j,cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = 0\n",
    "# scale = 10\n",
    "# for i in range(start, scale + (1 - start)):\n",
    "#     for j in range(start, scale + (1 - start) - i):\n",
    "#         k = scale - i - j\n",
    "#         print(i, j, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # showcasing Dirichlet distribution\n",
    "# def f(x):\n",
    "#     return x[0]**(a1-1) * x[1]**(a2-1) * x[2]**(a3-1)/beta\n",
    "\n",
    "# scale = 60\n",
    "# fig, tax = ternary.figure(scale=scale)\n",
    "# tax.heatmapf(f,scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def shannon_entropy(p):\n",
    "#     \"\"\"Computes the Shannon Entropy at a distribution in the simplex.\"\"\"\n",
    "#     s = 0.\n",
    "#     for i in range(len(p)):\n",
    "#         try:\n",
    "#             s += p[i] * log(p[i])\n",
    "#         except ValueError:\n",
    "#             continue\n",
    "#     return -1.*s\n",
    "# scale = 60\n",
    "\n",
    "# figure, tax = ternary.figure(scale=scale)\n",
    "# tax.heatmapf(shannon_entropy, boundary=True, style=\"triangular\")\n",
    "# tax.boundary(linewidth=2.0)\n",
    "# tax.set_title(\"Shannon Entropy Heatmap\")\n",
    "\n",
    "# tax.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
