{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal,beta,dirichlet, norm\n",
    "from math import log\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "np.random.seed(1234)\n",
    "from scipy.special import gamma\n",
    "import ternary\n",
    "\n",
    "\n",
    "np.set_printoptions(formatter={'all':lambda x: '%.3f' % x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1 = 50\n",
    "# a2 = 50\n",
    "# a3 = 50\n",
    "# beta = gamma(a1)*gamma(a2)*gamma(a3)/gamma(a1+a2+a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 10\n",
    "x1 = norm.rvs(-2,1,size=sz)\n",
    "x2 = norm.rvs(2,1,size=sz)\n",
    "x = np.hstack((x1,x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_id = np.zeros(x.shape)\n",
    "clusters,cluster_counts = np.unique(c_id,return_counts=True)\n",
    "n_cluster = len(clusters)\n",
    "\n",
    "sigma0 = 1\n",
    "mu0 = 0\n",
    "\n",
    "# sigma_cluster = np.array([sigma0])\n",
    "# mu_cluster = np.array([mu0])\n",
    "\n",
    "sigma_y = 1\n",
    "tau_y = 1/(sigma_y**2)\n",
    "ite = 30\n",
    "alpha = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rand_x = p0.rvs(size=2*sz)\n",
    "\n",
    "# rand_x_prob = dirichlet.pdf(rand_x,size=2*sz)\n",
    "\n",
    "# pred_x = norm.rvs(rand_x,sigma0,size=2*sz) * rand_x_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.958 -2.901]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m     cluster_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(cluster_counts,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     cluster_counts[new_c] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     43\u001b[0m c_id[i] \u001b[38;5;241m=\u001b[39m new_c\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# print(cluster_counts)\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "for _ in range(ite):\n",
    "    for i in range(sz*2):\n",
    "        \n",
    "        assign_id = int(c_id[i])\n",
    "        cluster_counts[assign_id] -= 1\n",
    "        if cluster_counts[assign_id] == 0:\n",
    "            cluster_counts[assign_id] = cluster_counts[-1]\n",
    "            c_id[np.where(c_id==n_cluster-1)[0]] = assign_id\n",
    "            clusters_counts = np.delete(cluster_counts, n_cluster-1) \n",
    "            n_cluster -= 1\n",
    "        c_id[i] = -1\n",
    "        # print(assign_id)\n",
    "        # print(cluster_counts)\n",
    "\n",
    "        logp = np.zeros((n_cluster+1))\n",
    "        for j in range(n_cluster):\n",
    "\n",
    "            idx = np.where(c_id == j)[0] # element indices within clusters[j]\n",
    "            y_average = np.mean(x[idx])\n",
    "            prior_tau_j = 1/(sigma0**2)\n",
    "            mu_j = (y_average*cluster_counts[j]* tau_y + mu0 * prior_tau_j )/ (cluster_counts[j]* tau_y + prior_tau_j )\n",
    "            sigma_j = np.sqrt(1/(cluster_counts[j]* tau_y + prior_tau_j ) + sigma_y**2)\n",
    "            \n",
    "            logp[j] = np.log(cluster_counts[j]/(sz*2-1+alpha)) + norm.logpdf(x[i],mu_j,sigma_j)\n",
    "        new_cluster_mu = mu0\n",
    "        new_cluster_sigma = np.sqrt(sigma0**2+sigma_y**2)\n",
    "        \n",
    "        logp[-1] = np.log(alpha/(sz*2-1+alpha)) + norm.logpdf(x[i],new_cluster_mu,new_cluster_sigma)\n",
    "        print(logp)\n",
    "        logp_max = np.max(logp)\n",
    "        logp = logp - logp_max\n",
    "        p = np.exp(logp)\n",
    "        p = p/np.sum(p)\n",
    "        \n",
    "        new_c = np.random.choice(np.arange(n_cluster+1),p=p)\n",
    "        if new_c == n_cluster:\n",
    "            # clusters = np.append(clusters,new_c)\n",
    "            n_cluster += 1\n",
    "            cluster_counts = np.append(cluster_counts,1)\n",
    "        else:\n",
    "            cluster_counts[new_c] += 1\n",
    "        c_id[i] = new_c\n",
    "        # print(cluster_counts)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.000 2.000 1.000 10.000 6.000 2.000 1.000 1.000 1.000 1.000 2.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000]\n"
     ]
    }
   ],
   "source": [
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = 0\n",
    "# scale = 10\n",
    "# for i in range(start, scale + (1 - start)):\n",
    "#     for j in range(start, scale + (1 - start) - i):\n",
    "#         k = scale - i - j\n",
    "#         print(i, j, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # showcasing Dirichlet distribution\n",
    "# def f(x):\n",
    "#     return x[0]**(a1-1) * x[1]**(a2-1) * x[2]**(a3-1)/beta\n",
    "\n",
    "# scale = 60\n",
    "# fig, tax = ternary.figure(scale=scale)\n",
    "# tax.heatmapf(f,scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def shannon_entropy(p):\n",
    "#     \"\"\"Computes the Shannon Entropy at a distribution in the simplex.\"\"\"\n",
    "#     s = 0.\n",
    "#     for i in range(len(p)):\n",
    "#         try:\n",
    "#             s += p[i] * log(p[i])\n",
    "#         except ValueError:\n",
    "#             continue\n",
    "#     return -1.*s\n",
    "# scale = 60\n",
    "\n",
    "# figure, tax = ternary.figure(scale=scale)\n",
    "# tax.heatmapf(shannon_entropy, boundary=True, style=\"triangular\")\n",
    "# tax.boundary(linewidth=2.0)\n",
    "# tax.set_title(\"Shannon Entropy Heatmap\")\n",
    "\n",
    "# tax.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
