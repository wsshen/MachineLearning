{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal,beta,dirichlet, norm\n",
    "from math import log\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "np.random.seed(1234)\n",
    "from scipy.special import gamma\n",
    "import ternary\n",
    "\n",
    "\n",
    "np.set_printoptions(formatter={'all':lambda x: '%.3f' % x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1 = 50\n",
    "# a2 = 50\n",
    "# a3 = 50\n",
    "# beta = gamma(a1)*gamma(a2)*gamma(a3)/gamma(a1+a2+a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 10\n",
    "x1 = norm.rvs(-2,1,size=sz)\n",
    "x2 = norm.rvs(2,1,size=sz)\n",
    "x = np.hstack((x1,x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.zeros(x.shape)\n",
    "clusters = np.ones(x.shape)\n",
    "cluster_assignment = np.arange(sz*2)\n",
    "p0 = norm(0,1)\n",
    "alpha = 10\n",
    "sigma0 = 2\n",
    "\n",
    "ite = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "print(clusters.shape)\n",
    "clusters = np.hstack((clusters[0:2],clusters[3:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_x = p0.rvs(size=2*sz)\n",
    "\n",
    "rand_x_prob = dirichlet.pdf(rand_x,size=2*sz)\n",
    "\n",
    "pred_x = norm.rvs(rand_x,sigma0,size=2*sz) * rand_x_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(ite):\n",
    "    for i in range(sz*2):\n",
    "        assign_id = cluster_assignment[i]\n",
    "        clusters[assign_id] = clusters[assign_id] - 1\n",
    "        if clusters[assign_id] == 0:\n",
    "            clusters = np.hstack((clusters[0:i],clusters[i+1:-1]))\n",
    "            means = np.hstack((means[0:i],means[i+1:-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = 0\n",
    "# scale = 10\n",
    "# for i in range(start, scale + (1 - start)):\n",
    "#     for j in range(start, scale + (1 - start) - i):\n",
    "#         k = scale - i - j\n",
    "#         print(i, j, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # showcasing Dirichlet distribution\n",
    "# def f(x):\n",
    "#     return x[0]**(a1-1) * x[1]**(a2-1) * x[2]**(a3-1)/beta\n",
    "\n",
    "# scale = 60\n",
    "# fig, tax = ternary.figure(scale=scale)\n",
    "# tax.heatmapf(f,scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def shannon_entropy(p):\n",
    "#     \"\"\"Computes the Shannon Entropy at a distribution in the simplex.\"\"\"\n",
    "#     s = 0.\n",
    "#     for i in range(len(p)):\n",
    "#         try:\n",
    "#             s += p[i] * log(p[i])\n",
    "#         except ValueError:\n",
    "#             continue\n",
    "#     return -1.*s\n",
    "# scale = 60\n",
    "\n",
    "# figure, tax = ternary.figure(scale=scale)\n",
    "# tax.heatmapf(shannon_entropy, boundary=True, style=\"triangular\")\n",
    "# tax.boundary(linewidth=2.0)\n",
    "# tax.set_title(\"Shannon Entropy Heatmap\")\n",
    "\n",
    "# tax.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import multivariate_normal\n",
    "\n",
    "np.random.seed(11)  # random seed set for reproducibility\n",
    "n = 60  # sampling 60 each from 4 separate distributions\n",
    "m1 = np.array([1.5, 1.5])  # upper right x, y means\n",
    "S1 = np.array([[0.3, 0.05], [0.05, 0.3]])  # variance of c1\n",
    "# sampling n from each cluster as per its mean mu and variance Sigma\n",
    "clus1 = multivariate_normal(mean=m1, cov=S1, size=n)\n",
    "m2 = np.array([1.5, -1.5])  # lower right\n",
    "S2 = np.array([[0.5, -0.08], [-0.08, 0.2]])\n",
    "clus2 = multivariate_normal(mean=m2, cov=S2, size=n)\n",
    "m3 = np.array([-1.5, 1.5])  # upper left\n",
    "S3 = np.array([[0.1, 0.03], [0.03, 0.1]])\n",
    "clus3 = multivariate_normal(mean=m3, cov=S3, size=n)\n",
    "m4 = np.array([-1.5, -1.5])  # lower left\n",
    "S4 = np.array([[0.8, 0.5], [0.5, 0.8]])\n",
    "clus4 = multivariate_normal(mean=m4, cov=S4, size=n)\n",
    "datc = np.vstack((clus1, clus2, clus3, clus4))  # 240 observations altogether\n",
    "\n",
    "# run the CRP Gibbs function in Appendix B.\n",
    "alpha = 0.01\n",
    "mu0 = np.zeros((1, 2))\n",
    "sigma0 = np.diag([3**2, 3**2])\n",
    "sigma_y = np.diag([1, 1])\n",
    "c_init = np.ones(datc.shape[0])\n",
    "z = c_init.copy()\n",
    "n_k = np.bincount(z.astype(int))\n",
    "Nclust = len(n_k)\n",
    "print(z)\n",
    "for n in range(len(z)):\n",
    "    c_i = int(z[n])\n",
    "    print(c_i)\n",
    "    n_k[c_i] -= 1\n",
    "    if n_k[c_i] == 0:\n",
    "        n_k[c_i] = n_k[Nclust - 1]  # last cluster to replace this empty cluster\n",
    "        loc_z = (z == Nclust)  # who are in the last cluster?\n",
    "        z[loc_z] = c_i  # move them up to fill just emptied cluster\n",
    "        n_k = np.delete(n_k, Nclust - 1)  # take out the last cluster, now empty\n",
    "        Nclust -= 1  # decrease total number of clusters by 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 2)\n"
     ]
    }
   ],
   "source": [
    "print(datc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
